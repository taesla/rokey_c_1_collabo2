#!/usr/bin/env python3
"""
Face Tracking Node - 2D ì¢Œí‘œë¥¼ 3D ë¡œë´‡ ì¢Œí‘œê³„ë¡œ ë³€í™˜

TF2ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¹´ë©”ë¼ ì¢Œí‘œê³„ â†’ ë¡œë´‡ ë² ì´ìŠ¤ ì¢Œí‘œê³„ ë³€í™˜

Subscribed Topics:
  /face_detection/faces - ì–¼êµ´ 2D ì¢Œí‘œ (from face_detection_node)
  /camera/camera/aligned_depth_to_color/image_raw - ê¹Šì´ ì´ë¯¸ì§€
  /camera/camera/color/camera_info - ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„°

Published Topics:
  /face_tracking/marker - RViz ë§ˆì»¤ (ì¹´ë©”ë¼ í”„ë ˆì„, ì´ˆë¡ìƒ‰)
  /face_tracking/marker_robot - RViz ë§ˆì»¤ (ë¡œë´‡ ë² ì´ìŠ¤ í”„ë ˆì„, ë¹¨ê°„ìƒ‰) â† ë¡œë´‡ ëª©í‘œ ìœ„ì¹˜!
  /face_tracking/line - ì¹´ë©”ë¼â†’ì–¼êµ´ ì—°ê²°ì„  (ë…¸ë€ìƒ‰)
"""
import math
import numpy as np
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image, CameraInfo
from std_msgs.msg import Float32MultiArray
from visualization_msgs.msg import Marker
from geometry_msgs.msg import Point, PointStamped
from cv_bridge import CvBridge
import tf2_ros
import tf2_geometry_msgs
from face_tracking_pkg.face_tracking_ekf import FaceTrackingEKF


class FaceTrackingNode(Node):
    def __init__(self):
        super().__init__('face_tracking_node')
        
        self.bridge = CvBridge()
        
        # íŒŒë¼ë¯¸í„° ì„ ì–¸
        self.declare_parameter('target_offset_mm', 650.0)
        self.declare_parameter('camera_frame', 'camera_color_optical_frame')
        self.declare_parameter('robot_frame', 'base_link')
        
        self.target_offset_mm = self.get_parameter('target_offset_mm').value
        self.camera_frame = self.get_parameter('camera_frame').value
        self.robot_frame = self.get_parameter('robot_frame').value
        
        # ë°ì´í„° ì €ì¥
        self.faces_data = []
        self.depth_frame = None
        self.intrinsics = None
        
        # TF2 ë²„í¼ ë° ë¦¬ìŠ¤ë„ˆ
        self.tf_buffer = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer, self)
        
        # êµ¬ë…ì
        self.faces_sub = self.create_subscription(
            Float32MultiArray, '/face_detection/faces', self.faces_callback, 10)
        self.depth_sub = self.create_subscription(
            Image, '/camera/camera/aligned_depth_to_color/image_raw', self.depth_callback, 10)
        self.camera_info_sub = self.create_subscription(
            CameraInfo, '/camera/camera/color/camera_info', self.camera_info_callback, 10)
        
        # ë°œí–‰ì
        self.marker_pub = self.create_publisher(Marker, '/face_tracking/marker', 10)
        self.marker_robot_pub = self.create_publisher(Marker, '/face_tracking/marker_robot', 10)
        self.marker_ekf_pub = self.create_publisher(Marker, '/face_tracking/marker_ekf', 10)  # EKF í•„í„°ë§ëœ ì¹´ë©”ë¼ í”„ë ˆì„
        # í…ìŠ¤íŠ¸ ì „ìš© í† í”½
        self.text_pub = self.create_publisher(Marker, '/face_tracking/text', 10)
        self.text_ekf_pub = self.create_publisher(Marker, '/face_tracking/text_ekf', 10)
        self.text_robot_pub = self.create_publisher(Marker, '/face_tracking/text_robot', 10)
        self.line_pub = self.create_publisher(Marker, '/face_tracking/line', 10)
        
        # EKF ì´ˆê¸°í™” (ì¹´ë©”ë¼ í”„ë ˆì„ ì¢Œí‘œ í•„í„°ë§ìš©)
        self.camera_ekf = FaceTrackingEKF(dt=0.033, dim=3)
        
        # ì–¼êµ´ ê°ì§€ ìƒíƒœ í”Œë˜ê·¸
        self.face_detected = False
        
        # íƒ€ì´ë¨¸: íŠ¸ë˜í‚¹ ë£¨í”„ (30Hz) - ë³‘ëª© í•´ê²°
        self.timer = self.create_timer(0.033, self.tracking_loop)
        
        # ì„±ëŠ¥ ì¸¡ì •
        self.loop_count = 0
        self.last_fps_time = self.get_clock().now()
        self.tracking_fps = 0.0
        
        self.get_logger().info("=" * 60)
        self.get_logger().info("ğŸ”„ Face Tracking Node (TF2) ì‹œì‘! [30Hz]")
        self.get_logger().info("  ğŸŸ¢ ì´ˆë¡ ë§ˆì»¤: ì¹´ë©”ë¼ í”„ë ˆì„")
        self.get_logger().info("  ğŸ”´ ë¹¨ê°„ ë§ˆì»¤: ë¡œë´‡ ë² ì´ìŠ¤ í”„ë ˆì„ (ëª©í‘œ)")
        self.get_logger().info("=" * 60)
    
    def faces_callback(self, msg):
        self.faces_data = list(msg.data)
    
    def depth_callback(self, msg):
        try:
            self.depth_frame = self.bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')
        except Exception as e:
            self.get_logger().error(f"ê¹Šì´ ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}")
    
    def camera_info_callback(self, msg):
        self.intrinsics = {
            'fx': msg.k[0], 'fy': msg.k[4],
            'ppx': msg.k[2], 'ppy': msg.k[5]
        }
    
    def get_3d_position(self, center_x, center_y):
        """2D í”½ì…€ ì¢Œí‘œ â†’ 3D ì¹´ë©”ë¼ ì¢Œí‘œ (mm)"""
        if self.depth_frame is None or self.intrinsics is None:
            return None
        
        x, y = int(center_x), int(center_y)
        h, w = self.depth_frame.shape
        
        if x < 10 or x >= w - 10 or y < 10 or y >= h - 10:
            return None
        
        # ê°œì„ : 9x9 ì˜ì—­ ì‚¬ìš© (3x3ëŠ” ë„ˆë¬´ ì‘ì•„ì„œ ë…¸ì´ì¦ˆì— ë¯¼ê°)
        depth_region = self.depth_frame[y-4:y+5, x-4:x+5]
        valid_depths = depth_region[depth_region > 0]
        
        if len(valid_depths) == 0:
            return None
        
        # ê°œì„ : Trimmed Mean (ìƒí•˜ìœ„ 20% ì œê±° í›„ í‰ê· )
        # medianë³´ë‹¤ ë¹ ë¥´ë©´ì„œë„ ì´ìƒì¹˜ì— ê°•ê±´
        if len(valid_depths) >= 5:
            valid_depths_sorted = np.sort(valid_depths)
            trim_count = max(1, len(valid_depths) // 5)  # 20% ì œê±°
            trimmed = valid_depths_sorted[trim_count:-trim_count]
            depth_mm = float(np.mean(trimmed))
        else:
            # ìƒ˜í”Œ ì ìœ¼ë©´ ê·¸ëƒ¥ mean
            depth_mm = float(np.mean(valid_depths))
        
        camera_x = (center_x - self.intrinsics['ppx']) * depth_mm / self.intrinsics['fx']
        camera_y = (center_y - self.intrinsics['ppy']) * depth_mm / self.intrinsics['fy']
        camera_z = depth_mm
        
        return np.array([camera_x, camera_y, camera_z])
    
    def camera_to_robot_tf2(self, camera_pos_mm):
        """TF2ë¥¼ ì‚¬ìš©í•´ ì¹´ë©”ë¼ ì¢Œí‘œ â†’ ë¡œë´‡ ë² ì´ìŠ¤ ì¢Œí‘œ ë³€í™˜"""
        try:
            point_camera = PointStamped()
            point_camera.header.frame_id = self.camera_frame
            point_camera.header.stamp = self.get_clock().now().to_msg()
            point_camera.point.x = camera_pos_mm[0] / 1000.0
            point_camera.point.y = camera_pos_mm[1] / 1000.0
            point_camera.point.z = camera_pos_mm[2] / 1000.0
            
            # ìµœì í™”: íƒ€ì„ì•„ì›ƒ ë‹¨ì¶• (0.1ì´ˆ â†’ 0.01ì´ˆ)
            transform = self.tf_buffer.lookup_transform(
                self.robot_frame, self.camera_frame,
                rclpy.time.Time(),
                timeout=rclpy.duration.Duration(seconds=0.01)
            )
            
            point_base = tf2_geometry_msgs.do_transform_point(point_camera, transform)
            
            return np.array([
                point_base.point.x * 1000.0,
                point_base.point.y * 1000.0,
                point_base.point.z * 1000.0
            ])
            
        except (tf2_ros.LookupException, tf2_ros.ConnectivityException, 
                tf2_ros.ExtrapolationException) as e:
            self.get_logger().warn(f"TF2 ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None
    
    def delete_all_markers(self):
        """ëª¨ë“  ë§ˆì»¤ì™€ í…ìŠ¤íŠ¸ë¥¼ ì‚­ì œ"""
        marker_ids = [
            (self.marker_pub, "face_camera"),
            (self.text_pub, "face_camera_text"),
            (self.marker_ekf_pub, "face_camera_ekf"),
            (self.text_ekf_pub, "face_camera_ekf_text"),
            (self.marker_robot_pub, "face_robot_target"),
            (self.text_robot_pub, "face_robot_text"),
            (self.line_pub, "face_line")
        ]
        
        for pub, ns in marker_ids:
            marker = Marker()
            marker.header.frame_id = self.robot_frame
            marker.header.stamp = self.get_clock().now().to_msg()
            marker.ns = ns
            marker.id = 0
            marker.action = Marker.DELETE
            pub.publish(marker)
    
    def publish_camera_marker(self, camera_pos):
        """ì¹´ë©”ë¼ í”„ë ˆì„ ë§ˆì»¤ (ì´ˆë¡ìƒ‰ íë¸Œ) - base_link í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ í‘œì‹œ"""
        # TF ë³€í™˜ìœ¼ë¡œ base_link ì¢Œí‘œ ì–»ê¸°
        robot_pos = self.camera_to_robot_tf2(camera_pos)
        if robot_pos is None:
            return
        
        marker = Marker()
        marker.header.frame_id = self.robot_frame  # base_link ì‚¬ìš©
        marker.header.stamp = self.get_clock().now().to_msg()
        marker.ns = "face_camera"
        marker.id = 0
        marker.type = Marker.CUBE
        marker.action = Marker.ADD
        marker.pose.position.x = robot_pos[0] / 1000.0
        marker.pose.position.y = robot_pos[1] / 1000.0
        marker.pose.position.z = robot_pos[2] / 1000.0
        marker.pose.orientation.w = 1.0
        marker.scale.x = marker.scale.y = marker.scale.z = 0.08
        marker.color.r, marker.color.g, marker.color.b, marker.color.a = 0.0, 1.0, 0.0, 0.5
        marker.lifetime.sec = 0
        marker.lifetime.nanosec = 500000000  # 0.5ì´ˆ
        self.marker_pub.publish(marker)
        
        # í…ìŠ¤íŠ¸ ë§ˆì»¤ (ë³„ë„ í† í”½) - base_link
        text = Marker()
        text.header.frame_id = self.robot_frame
        text.header.stamp = self.get_clock().now().to_msg()
        text.ns = "face_camera_text"
        text.id = 0
        text.type = Marker.TEXT_VIEW_FACING
        text.action = Marker.ADD
        text.pose.position.x = robot_pos[0] / 1000.0
        text.pose.position.y = robot_pos[1] / 1000.0
        text.pose.position.z = robot_pos[2] / 1000.0 + 0.08
        text.pose.orientation.w = 1.0
        text.scale.z = 0.04
        text.color.r, text.color.g, text.color.b, text.color.a = 0.0, 1.0, 0.0, 1.0
        text.text = "Raw"
        text.lifetime.sec = 0
        text.lifetime.nanosec = 500000000  # 0.5ì´ˆ
        self.text_pub.publish(text)
    
    def publish_camera_ekf_marker(self, filtered_pos):
        """ì¹´ë©”ë¼ í”„ë ˆì„ EKF í•„í„°ë§ ë§ˆì»¤ (ì²­ë¡ìƒ‰ íë¸Œ) - base_link í”„ë ˆì„ìœ¼ë¡œ ë³€í™˜"""
        # TF ë³€í™˜ìœ¼ë¡œ base_link ì¢Œí‘œ ì–»ê¸°
        robot_pos = self.camera_to_robot_tf2(filtered_pos)
        if robot_pos is None:
            return
        
        marker = Marker()
        marker.header.frame_id = self.robot_frame  # base_link ì‚¬ìš©
        marker.header.stamp = self.get_clock().now().to_msg()
        marker.ns = "face_camera_ekf"
        marker.id = 0
        marker.type = Marker.CUBE
        marker.action = Marker.ADD
        marker.pose.position.x = robot_pos[0] / 1000.0
        marker.pose.position.y = robot_pos[1] / 1000.0
        marker.pose.position.z = robot_pos[2] / 1000.0
        marker.pose.orientation.w = 1.0
        marker.scale.x = marker.scale.y = marker.scale.z = 0.10
        marker.color.r, marker.color.g, marker.color.b, marker.color.a = 0.0, 0.8, 0.8, 0.5
        marker.lifetime.sec = 0
        marker.lifetime.nanosec = 500000000  # 0.5ì´ˆ
        self.marker_ekf_pub.publish(marker)
        
        # í…ìŠ¤íŠ¸ ë§ˆì»¤ (ë³„ë„ í† í”½) - base_link
        text = Marker()
        text.header.frame_id = self.robot_frame
        text.header.stamp = self.get_clock().now().to_msg()
        text.ns = "face_camera_ekf_text"
        text.id = 0
        text.type = Marker.TEXT_VIEW_FACING
        text.action = Marker.ADD
        text.pose.position.x = robot_pos[0] / 1000.0
        text.pose.position.y = robot_pos[1] / 1000.0
        text.pose.position.z = robot_pos[2] / 1000.0 + 0.10
        text.pose.orientation.w = 1.0
        text.scale.z = 0.04
        text.color.r, text.color.g, text.color.b, text.color.a = 0.0, 1.0, 1.0, 1.0
        text.text = "Filtered"
        text.lifetime.sec = 0
        text.lifetime.nanosec = 500000000  # 0.5ì´ˆ
        self.text_ekf_pub.publish(text)
    
    def publish_robot_marker(self, robot_pos):
        """ë¡œë´‡ ë² ì´ìŠ¤ í”„ë ˆì„ ë§ˆì»¤ (ë¹¨ê°„ìƒ‰ íë¸Œ)"""
        marker = Marker()
        marker.header.frame_id = self.robot_frame
        marker.header.stamp = self.get_clock().now().to_msg()
        marker.ns = "face_robot_target"
        marker.id = 0
        marker.type = Marker.CUBE
        marker.action = Marker.ADD
        marker.pose.position.x = robot_pos[0] / 1000.0
        marker.pose.position.y = robot_pos[1] / 1000.0
        marker.pose.position.z = robot_pos[2] / 1000.0
        marker.pose.orientation.w = 1.0
        marker.scale.x = marker.scale.y = marker.scale.z = 0.10
        marker.color.r, marker.color.g, marker.color.b, marker.color.a = 1.0, 0.0, 0.0, 0.5
        marker.lifetime.sec = 0
        marker.lifetime.nanosec = 500000000  # 0.5ì´ˆ
        self.marker_robot_pub.publish(marker)
        
        # í…ìŠ¤íŠ¸ ë§ˆì»¤ (ë³„ë„ í† í”½)
        text = Marker()
        text.header.frame_id = self.robot_frame
        text.header.stamp = self.get_clock().now().to_msg()
        text.ns = "face_robot_text"
        text.id = 0
        text.type = Marker.TEXT_VIEW_FACING
        text.action = Marker.ADD
        text.pose.position.x = robot_pos[0] / 1000.0
        text.pose.position.y = robot_pos[1] / 1000.0
        text.pose.position.z = robot_pos[2] / 1000.0 + 0.10
        text.pose.orientation.w = 1.0
        text.scale.z = 0.05
        text.color.r, text.color.g, text.color.b, text.color.a = 1.0, 0.0, 0.0, 1.0
        text.text = "Target"
        text.lifetime.sec = 0
        text.lifetime.nanosec = 500000000  # 0.5ì´ˆ
        self.text_robot_pub.publish(text)
    
    def publish_line_marker(self, camera_pos):
        """
        ì¹´ë©”ë¼â†’ì–¼êµ´ íˆ¬ì˜ ë¼ì¸ (ë…¸ë€ìƒ‰) 
        ê³µí•™ì ìœ¼ë¡œ ì •í™•í•œ íˆ¬ì˜: RGB ë Œì¦ˆ ì¤‘ì‹¬ â†’ ì–¼êµ´ ìœ„ì¹˜
        base_link í”„ë ˆì„ì—ì„œ TF ë³€í™˜ì„ ì‚¬ìš©í•˜ì—¬ ì •í™•íˆ ë§ˆì»¤ ì¤‘ì‹¬ì„ í†µê³¼
        """
        try:
            # RGB ë Œì¦ˆ ìœ„ì¹˜ë¥¼ camera_link í”„ë ˆì„ì—ì„œ base_linkë¡œ ë³€í™˜
            # D435i: RGB ë Œì¦ˆëŠ” camera_link ì¤‘ì‹¬ì—ì„œ ì•½ Y=-15mm ìœ„ì¹˜
            transform = self.tf_buffer.lookup_transform(
                self.robot_frame,  # base_link
                "camera_link",
                rclpy.time.Time(),
                timeout=rclpy.duration.Duration(seconds=0.1)
            )
            
            # RGB ë Œì¦ˆ ìœ„ì¹˜ (camera_link ê¸°ì¤€: Y=-15mm)
            # camera_link: X=ì•, Y=ì™¼ìª½, Z=ìœ„
            from geometry_msgs.msg import PointStamped
            rgb_point = PointStamped()
            rgb_point.header.frame_id = "camera_link"
            rgb_point.header.stamp = self.get_clock().now().to_msg()
            rgb_point.point.x = 0.0
            rgb_point.point.y = -0.015  # RGB ë Œì¦ˆ ì˜¤í”„ì…‹ (camera_linkì—ì„œ ì˜¤ë¥¸ìª½)
            rgb_point.point.z = 0.0
            
            # TF ë³€í™˜
            from tf2_geometry_msgs import do_transform_point
            rgb_transformed = do_transform_point(rgb_point, transform)
            
            rgb_origin_robot = [
                rgb_transformed.point.x * 1000.0,
                rgb_transformed.point.y * 1000.0,
                rgb_transformed.point.z * 1000.0
            ]
        except Exception as e:
            self.get_logger().warn(f"RGB lens TF failed: {e}", throttle_duration_sec=5.0)
            return
        
        # ì–¼êµ´ ìœ„ì¹˜ë„ TF ë³€í™˜
        face_pos_robot = self.camera_to_robot_tf2(camera_pos)
        if face_pos_robot is None:
            return
        
        marker = Marker()
        marker.header.frame_id = self.robot_frame  # base_link
        marker.header.stamp = self.get_clock().now().to_msg()
        marker.ns = "face_line"
        marker.id = 2
        marker.type = Marker.LINE_STRIP
        marker.action = Marker.ADD
        
        # p1: RGB ë Œì¦ˆ ì¤‘ì‹¬ (base_link ì¢Œí‘œ)
        p1 = Point()
        p1.x = rgb_origin_robot[0] / 1000.0
        p1.y = rgb_origin_robot[1] / 1000.0
        p1.z = rgb_origin_robot[2] / 1000.0
        
        # p2: ì–¼êµ´ ìœ„ì¹˜ (base_link ì¢Œí‘œ)
        p2 = Point()
        p2.x = face_pos_robot[0] / 1000.0
        p2.y = face_pos_robot[1] / 1000.0
        p2.z = face_pos_robot[2] / 1000.0
        
        marker.points = [p1, p2]
        marker.scale.x = 0.01
        marker.color.r, marker.color.g, marker.color.b, marker.color.a = 1.0, 1.0, 0.0, 1.0
        marker.lifetime.nanosec = 500000000
        self.line_pub.publish(marker)
    
    def tracking_loop(self):
        """ë©”ì¸ íŠ¸ë˜í‚¹ ë£¨í”„ (30Hz)"""
        # FPS ì¸¡ì •
        self.loop_count += 1
        current_time = self.get_clock().now()
        time_diff = (current_time - self.last_fps_time).nanoseconds / 1e9
        
        # ì„±ê³µ/ì‹¤íŒ¨ ì¹´ìš´í„° ì´ˆê¸°í™”
        if not hasattr(self, 'success_count'):
            self.success_count = 0
            self.fail_count = 0
        
        if time_diff >= 1.0:
            self.tracking_fps = self.loop_count / time_diff
            success_rate = (self.success_count / self.loop_count * 100) if self.loop_count > 0 else 0
            self.get_logger().info(
                f"ğŸ“Š Loop: {self.tracking_fps:.1f}Hz | "
                f"3D Success: {self.success_count}/{self.loop_count} ({success_rate:.1f}%)"
            )
            self.loop_count = 0
            self.success_count = 0
            self.fail_count = 0
            self.last_fps_time = current_time
        
        # ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨ ì‹œ ëª¨ë“  ë§ˆì»¤ ì‚­ì œ
        if len(self.faces_data) < 4:
            if self.face_detected:  # ì´ì „ì— ê°ì§€ë˜ì—ˆë‹¤ë©´ ì‚­ì œ ë§ˆì»¤ ë°œí–‰
                self.delete_all_markers()
                self.face_detected = False
            return
        
        self.face_detected = True
        
        center_x, center_y = self.faces_data[0], self.faces_data[1]
        
        camera_pos = self.get_3d_position(center_x, center_y)
        if camera_pos is None:
            self.fail_count += 1
            return
        
        self.success_count += 1
        
        # EKF ì—…ë°ì´íŠ¸ (ì¸¡ì •ê°’ìœ¼ë¡œ ë³´ì •)
        camera_pos_array = np.array(camera_pos)
        
        if not self.camera_ekf.initialized:
            self.camera_ekf.initialize(camera_pos_array.tolist())
        else:
            # Predict & Update
            self.camera_ekf.predict()
            self.camera_ekf.update(camera_pos_array.tolist())
        
        # Raw ì´ˆë¡ìƒ‰ ë§ˆì»¤ (ì›ë³¸)
        self.publish_camera_marker(camera_pos)
        
        # EKF ì²­ë¡ìƒ‰ ë§ˆì»¤ (ì¸¡ì •ê°’ ìˆì„ ë•Œë§Œ)
        filtered_camera_pos = self.camera_ekf.get_position()
        self.publish_camera_ekf_marker(filtered_camera_pos)
        
        # Line ë§ˆì»¤ë„ EKF í•„í„°ëœ ìœ„ì¹˜ ì‚¬ìš© (ì²­ë¡ìƒ‰ ë§ˆì»¤ì™€ ì‹±í¬)
        self.publish_line_marker(filtered_camera_pos)
        
        # ëª©í‘œ ìœ„ì¹˜ = í•„í„°ëœ ì–¼êµ´ ìœ„ì¹˜ì—ì„œ ì•ˆì „ê±°ë¦¬ë§Œí¼ ë–¨ì–´ì§„ ìœ„ì¹˜
        depth = abs(filtered_camera_pos[2])  # Zì¶• ê¹Šì´ (mm)
        if depth < 100.0:  # 10cm ë¯¸ë§Œì€ ë¬´ì‹œ
            return
        
        # ì•ˆì „ê±°ë¦¬: 590mm (ì–¼êµ´ì—ì„œ 59cm ë–¨ì–´ì§„ ìœ„ì¹˜ê°€ ëª©í‘œ)
        safety_distance = 590.0
        distance = np.linalg.norm(filtered_camera_pos)
        direction = filtered_camera_pos / distance
        
        # ëª©í‘œ = ì–¼êµ´ì—ì„œ ì•ˆì „ê±°ë¦¬ë§Œí¼ ì¹´ë©”ë¼ ë°©í–¥ìœ¼ë¡œ
        target_camera_pos = filtered_camera_pos - direction * safety_distance
        
        robot_pos_xyz = self.camera_to_robot_tf2(target_camera_pos)
        if robot_pos_xyz is None:
            return
        
        # ============================================
        # ì•ˆì „êµ¬ì—­ í´ë¨í•‘ (Targetì´ ì•ˆì „ ë²”ìœ„ ë‚´ì— ìˆë„ë¡)
        # ============================================
        # ë¡œë´‡ ë„ë‹¬ ê°€ëŠ¥ ë²”ìœ„ (m0609: 900mm reach)
        safe_r_min = 300.0   # ìµœì†Œ ë°˜ê²½ (mm) - ë¡œë´‡ ëª¸í†µ ì¶©ëŒ ë°©ì§€
        safe_r_max = 850.0   # ìµœëŒ€ ë°˜ê²½ (mm) - ë„ë‹¬ í•œê³„
        safe_z_min = 150.0   # ìµœì†Œ ë†’ì´ (mm) - í…Œì´ë¸” ì¶©ëŒ ë°©ì§€
        safe_z_max = 800.0   # ìµœëŒ€ ë†’ì´ (mm)
        
        # XY í‰ë©´ ë°˜ê²½ ê³„ì‚°
        r_xy = np.sqrt(robot_pos_xyz[0]**2 + robot_pos_xyz[1]**2)
        
        # ë°˜ê²½ í´ë¨í•‘
        if r_xy < safe_r_min:
            scale = safe_r_min / r_xy if r_xy > 0 else 1.0
            robot_pos_xyz[0] *= scale
            robot_pos_xyz[1] *= scale
            self.get_logger().warn(f"âš ï¸ Target ë°˜ê²½ í´ë¨í•‘: {r_xy:.0f} â†’ {safe_r_min:.0f}mm", throttle_duration_sec=2.0)
        elif r_xy > safe_r_max:
            scale = safe_r_max / r_xy
            robot_pos_xyz[0] *= scale
            robot_pos_xyz[1] *= scale
            self.get_logger().warn(f"âš ï¸ Target ë°˜ê²½ í´ë¨í•‘: {r_xy:.0f} â†’ {safe_r_max:.0f}mm", throttle_duration_sec=2.0)
        
        # Z ë†’ì´ í´ë¨í•‘
        if robot_pos_xyz[2] < safe_z_min:
            self.get_logger().warn(f"âš ï¸ Target Z í´ë¨í•‘: {robot_pos_xyz[2]:.0f} â†’ {safe_z_min:.0f}mm", throttle_duration_sec=2.0)
            robot_pos_xyz[2] = safe_z_min
        elif robot_pos_xyz[2] > safe_z_max:
            self.get_logger().warn(f"âš ï¸ Target Z í´ë¨í•‘: {robot_pos_xyz[2]:.0f} â†’ {safe_z_max:.0f}mm", throttle_duration_sec=2.0)
            robot_pos_xyz[2] = safe_z_max
        
        # ë””ë²„ê·¸: ëª©í‘œ ìœ„ì¹˜ ë¡œê·¸
        self.get_logger().info(
            f"ğŸ“ Target: [{robot_pos_xyz[0]:.0f}, {robot_pos_xyz[1]:.0f}, {robot_pos_xyz[2]:.0f}]mm | "
            f"Depth: {depth:.0f}mm, Safety: {safety_distance:.0f}mm",
            throttle_duration_sec=1.0
        )
        
        # TCP íšŒì „ ê³„ì‚° (ì–¼êµ´ì„ í–¥í•˜ë„ë¡) - EKF í•„í„°ë§ëœ ìœ„ì¹˜ ì‚¬ìš©!
        # Zì¶• ê¸°ì¤€ íšŒì „ (íŒ” ëì´ ì–¼êµ´ì„ ê°€ë¦¬í‚¤ë„ë¡)
        face_robot_pos = self.camera_to_robot_tf2(filtered_camera_pos)
        if face_robot_pos is not None:
            # ëª©í‘œì—ì„œ ì–¼êµ´ë¡œì˜ ë°©í–¥
            vec_to_face = np.array(face_robot_pos) - np.array(robot_pos_xyz)
            distance_to_face = np.linalg.norm(vec_to_face)
            if distance_to_face > 10.0:
                # Zì¶• íšŒì „ (Yaw) ê³„ì‚°
                rz = math.degrees(math.atan2(vec_to_face[1], vec_to_face[0]))
                # Yì¶• íšŒì „ (Pitch) ê³„ì‚°
                ry = -math.degrees(math.atan2(vec_to_face[2], math.sqrt(vec_to_face[0]**2 + vec_to_face[1]**2)))
                robot_pos = robot_pos_xyz + [0.0, ry, rz]
            else:
                robot_pos = robot_pos_xyz + [0.0, 0.0, 0.0]
        else:
            robot_pos = robot_pos_xyz + [0.0, 0.0, 0.0]
        
        self.publish_robot_marker(robot_pos[:3])  # XYZë§Œ ë§ˆì»¤ë¡œ


def main(args=None):
    rclpy.init(args=args)
    node = FaceTrackingNode()
    
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        if rclpy.ok():
            rclpy.shutdown()


if __name__ == "__main__":
    main()
