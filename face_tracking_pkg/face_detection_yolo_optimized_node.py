#!/usr/bin/env python3
"""
Face Detection Node - YOLOv8 Optimized Version

ê³ ê¸‰ ìµœì í™” ì ìš©:
1. TensorRT ì—”ì§„ ìë™ ë³€í™˜ (NVIDIA GPU)
2. FP16 Half Precision ì¶”ë¡ 
3. ê³ í•´ìƒë„ ì…ë ¥ (1280px)
4. íˆìŠ¤í† ê·¸ë¨ í‰í™œí™” ì „ì²˜ë¦¬
5. NMS ìµœì í™”
6. ë©€í‹°ìŠ¤ì¼€ì¼ ê²€ì¶œ
7. ROI ê¸°ë°˜ ë¹ ë¥¸ ì¶”ì 

Subscribed Topics:
  /camera/camera/color/image_raw - RealSense ì»¬ëŸ¬ ì´ë¯¸ì§€

Published Topics:
  /face_detection/image - ì–¼êµ´ í‘œì‹œëœ ì´ë¯¸ì§€
  /face_detection/faces - ì–¼êµ´ ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸ [center_x, center_y, w, h, ...]
"""
import cv2
import numpy as np
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from std_msgs.msg import Float32MultiArray
from cv_bridge import CvBridge
from ultralytics import YOLO
import os
import time


class FaceDetectionYoloOptimizedNode(Node):
    def __init__(self):
        super().__init__('face_detection_node')
        
        self.bridge = CvBridge()
        self.current_frame = None
        
        # íŒŒë¼ë¯¸í„° ì„ ì–¸
        self.declare_parameter('model_path', '')
        self.declare_parameter('confidence_threshold', 0.4)  # ë‚®ì¶°ì„œ ë¯¼ê°í•˜ê²Œ
        self.declare_parameter('show_window', False)
        self.declare_parameter('use_gpu', True)
        self.declare_parameter('use_tensorrt', True)  # TensorRT ì‚¬ìš©
        self.declare_parameter('use_fp16', True)  # FP16 ì¶”ë¡ 
        self.declare_parameter('input_size', 1280)  # ê³ í•´ìƒë„ ì…ë ¥
        self.declare_parameter('use_preprocessing', True)  # ì „ì²˜ë¦¬ ì ìš©
        self.declare_parameter('use_roi_tracking', True)  # ROI ê¸°ë°˜ ì¶”ì 
        
        model_path = self.get_parameter('model_path').value
        self.confidence_threshold = self.get_parameter('confidence_threshold').value
        self.show_window = self.get_parameter('show_window').value
        use_gpu = self.get_parameter('use_gpu').value
        self.use_tensorrt = self.get_parameter('use_tensorrt').value
        self.use_fp16 = self.get_parameter('use_fp16').value
        self.input_size = self.get_parameter('input_size').value
        self.use_preprocessing = self.get_parameter('use_preprocessing').value
        self.use_roi_tracking = self.get_parameter('use_roi_tracking').value
        
        # ëª¨ë¸ ê²½ë¡œ ì°¾ê¸°
        if not model_path or not os.path.exists(model_path):
            package_dir = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
            model_path = os.path.join(package_dir, 'models', 'yolov8n-face.pt')
            
            if not os.path.exists(model_path):
                model_path = '/home/rokey/ros2_ws/src/face_tracking_pkg/models/yolov8n-face.pt'
        
        if not os.path.exists(model_path):
            self.get_logger().error(f"âŒ ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            raise FileNotFoundError(f"Model not found: {model_path}")
        
        # GPU í™•ì¸
        self.device = 'cpu'
        self.cuda_available = False
        
        if use_gpu:
            try:
                import torch
                if torch.cuda.is_available():
                    self.device = 'cuda'
                    self.cuda_available = True
                    gpu_name = torch.cuda.get_device_name(0)
                    self.get_logger().info(f"ğŸš€ GPU ê°ì§€: {gpu_name}")
                else:
                    self.get_logger().warn("âš ï¸ GPU ì‚¬ìš© ë¶ˆê°€, CPU ëª¨ë“œë¡œ ì‹¤í–‰")
                    self.use_tensorrt = False
                    self.use_fp16 = False
            except Exception as e:
                self.get_logger().warn(f"âš ï¸ PyTorch CUDA í™•ì¸ ì‹¤íŒ¨: {e}")
                self.use_tensorrt = False
                self.use_fp16 = False
        
        # TensorRT ì—”ì§„ ë¡œë“œ ë˜ëŠ” ìƒì„±
        self.model = self._load_optimized_model(model_path)
        
        # ì„±ëŠ¥ ì¸¡ì •ìš©
        self.frame_count = 0
        self.fps = 0.0
        self.last_fps_time = self.get_clock().now()
        self.inference_times = []
        self.avg_inference_time = 0.0
        
        # ì‹ ë¢°ë„ íˆìŠ¤í† ë¦¬ (ì•ˆì •ì„± í–¥ìƒ)
        self.confidence_history = []
        self.history_size = 5
        
        # ì´ì „ ê²€ì¶œ ê²°ê³¼ (ê¹œë¹¡ì„ ë°©ì§€)
        self.last_detection = None
        self.no_detection_count = 0
        self.max_no_detection = 5  # 5í”„ë ˆì„ê¹Œì§€ ì´ì „ ê²°ê³¼ ìœ ì§€
        
        # ROI ê¸°ë°˜ ì¶”ì  (ë¹ ë¥¸ ê²€ì¶œ)
        self.last_roi = None
        self.roi_margin = 100  # ROI ë§ˆì§„ (í”½ì…€)
        self.roi_fail_count = 0
        self.max_roi_fail = 3
        
        # CLAHE (ì ì‘í˜• íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”)
        self.clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        
        # RealSense ì´ë¯¸ì§€ í† í”½ êµ¬ë…
        self.image_sub = self.create_subscription(
            Image,
            '/camera/camera/color/image_raw',
            self.image_callback,
            10
        )
        
        # í¼ë¸”ë¦¬ì…”
        self.image_pub = self.create_publisher(Image, '/face_detection/image', 10)
        self.faces_pub = self.create_publisher(Float32MultiArray, '/face_detection/faces', 10)
        
        # íƒ€ì´ë¨¸ (30Hz)
        self.timer = self.create_timer(0.033, self.process_loop)
        
        self._print_startup_info()
    
    def _load_optimized_model(self, model_path):
        """ìµœì í™”ëœ ëª¨ë¸ ë¡œë“œ (TensorRT ìš°ì„ )"""
        
        # TensorRT ì—”ì§„ ê²½ë¡œ
        engine_path = model_path.replace('.pt', '.engine')
        
        if self.use_tensorrt and self.cuda_available:
            if os.path.exists(engine_path):
                # ê¸°ì¡´ TensorRT ì—”ì§„ ì‚¬ìš©
                self.get_logger().info(f"ğŸ”¥ TensorRT ì—”ì§„ ë¡œë”©: {engine_path}")
                try:
                    model = YOLO(engine_path)
                    self.get_logger().info("âœ… TensorRT ì—”ì§„ ë¡œë“œ ì„±ê³µ!")
                    return model
                except Exception as e:
                    self.get_logger().warn(f"âš ï¸ TensorRT ì—”ì§„ ë¡œë“œ ì‹¤íŒ¨: {e}")
            
            # TensorRT ì—”ì§„ ìƒì„± ì‹œë„
            self.get_logger().info(f"ğŸ”„ YOLO ëª¨ë¸ ë¡œë”© ë° TensorRT ë³€í™˜ ì‹œë„...")
            try:
                model = YOLO(model_path)
                self.get_logger().info("ğŸ”§ TensorRT ì—”ì§„ ìƒì„± ì¤‘... (ìµœì´ˆ 1íšŒ, 1-2ë¶„ ì†Œìš”)")
                
                # TensorRT export
                model.export(
                    format='engine',
                    half=self.use_fp16,
                    imgsz=self.input_size,
                    device=0
                )
                
                if os.path.exists(engine_path):
                    self.get_logger().info("âœ… TensorRT ì—”ì§„ ìƒì„± ì™„ë£Œ!")
                    model = YOLO(engine_path)
                    return model
                    
            except Exception as e:
                self.get_logger().warn(f"âš ï¸ TensorRT ë³€í™˜ ì‹¤íŒ¨: {e}")
                self.get_logger().info("ğŸ“Œ ì¼ë°˜ YOLO ëª¨ë¸ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤.")
        
        # ì¼ë°˜ YOLO ëª¨ë¸ ë¡œë“œ
        self.get_logger().info(f"ğŸ”„ YOLO ëª¨ë¸ ë¡œë”©: {model_path}")
        model = YOLO(model_path)
        
        return model
    
    def _print_startup_info(self):
        """ì‹œì‘ ì •ë³´ ì¶œë ¥"""
        self.get_logger().info("=" * 60)
        self.get_logger().info("ğŸ¥ Face Detection Node (YOLOv8 Optimized) ì‹œì‘!")
        self.get_logger().info(f"  Device: {self.device.upper()}")
        self.get_logger().info(f"  TensorRT: {'âœ… í™œì„±í™”' if self.use_tensorrt and self.cuda_available else 'âŒ ë¹„í™œì„±í™”'}")
        self.get_logger().info(f"  FP16: {'âœ… í™œì„±í™”' if self.use_fp16 and self.cuda_available else 'âŒ ë¹„í™œì„±í™”'}")
        self.get_logger().info(f"  Input Size: {self.input_size}px")
        self.get_logger().info(f"  Preprocessing: {'âœ…' if self.use_preprocessing else 'âŒ'}")
        self.get_logger().info(f"  ROI Tracking: {'âœ…' if self.use_roi_tracking else 'âŒ'}")
        self.get_logger().info(f"  Confidence: {self.confidence_threshold}")
        self.get_logger().info("  Published Topics:")
        self.get_logger().info("    /face_detection/image")
        self.get_logger().info("    /face_detection/faces")
        self.get_logger().info("=" * 60)
    
    def image_callback(self, msg):
        """ROS2 ì´ë¯¸ì§€ ë©”ì‹œì§€ë¥¼ OpenCV ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
        try:
            self.current_frame = self.bridge.imgmsg_to_cv2(msg, "bgr8")
        except Exception as e:
            self.get_logger().error(f"ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}")
    
    def _preprocess_image(self, frame):
        """ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (ì¡°ëª… ë³´ì •)"""
        if not self.use_preprocessing:
            return frame
        
        # LAB ìƒ‰ê³µê°„ìœ¼ë¡œ ë³€í™˜
        lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)
        
        # L ì±„ë„ì— CLAHE ì ìš© (ì ì‘í˜• íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”)
        lab[:, :, 0] = self.clahe.apply(lab[:, :, 0])
        
        # BGRë¡œ ë‹¤ì‹œ ë³€í™˜
        enhanced = cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
        
        return enhanced
    
    def _get_roi(self, frame_shape):
        """ROI ì˜ì—­ ê³„ì‚° (ì´ì „ ê²€ì¶œ ê¸°ë°˜)"""
        if not self.use_roi_tracking or self.last_detection is None:
            return None
        
        h, w = frame_shape[:2]
        det = self.last_detection
        
        # ROI ê³„ì‚° (ë§ˆì§„ í¬í•¨)
        x1 = max(0, det['x1'] - self.roi_margin)
        y1 = max(0, det['y1'] - self.roi_margin)
        x2 = min(w, det['x2'] + self.roi_margin)
        y2 = min(h, det['y2'] + self.roi_margin)
        
        # ìµœì†Œ í¬ê¸° ë³´ì¥
        if (x2 - x1) < 100 or (y2 - y1) < 100:
            return None
        
        return (x1, y1, x2, y2)
    
    def _detect_in_roi(self, frame, roi):
        """ROI ì˜ì—­ì—ì„œ ê²€ì¶œ"""
        x1, y1, x2, y2 = roi
        roi_frame = frame[y1:y2, x1:x2]
        
        # ROIì—ì„œ ì¶”ë¡ 
        results = self.model.predict(
            roi_frame,
            conf=self.confidence_threshold,
            device=self.device,
            half=self.use_fp16 and self.cuda_available,
            verbose=False
        )
        
        # ê²°ê³¼ì™€ ROI ì˜¤í”„ì…‹ì„ í•¨ê»˜ ë°˜í™˜ (inplace ìˆ˜ì • ëŒ€ì‹ )
        return results, (x1, y1)
    
    def _detect_full_frame(self, frame):
        """ì „ì²´ í”„ë ˆì„ì—ì„œ ê²€ì¶œ"""
        results = self.model.predict(
            frame,
            conf=self.confidence_threshold,
            device=self.device,
            imgsz=self.input_size,
            half=self.use_fp16 and self.cuda_available,
            verbose=False
        )
        return results
    
    def process_loop(self):
        """ì–¼êµ´ ê°ì§€ ë° í¼ë¸”ë¦¬ì‹œ"""
        if self.current_frame is None:
            return
        
        frame = self.current_frame.copy()
        h, w, _ = frame.shape
        
        # ì „ì²˜ë¦¬
        processed_frame = self._preprocess_image(frame)
        
        # ì¶”ë¡  ì‹œê°„ ì¸¡ì • ì‹œì‘
        start_time = time.time()
        
        # ROI ê¸°ë°˜ ê²€ì¶œ ì‹œë„
        results = None
        roi_offset = (0, 0)  # ROI ì˜¤í”„ì…‹ (x, y)
        roi = self._get_roi(frame.shape)
        
        if roi is not None:
            results, roi_offset = self._detect_in_roi(processed_frame, roi)
            
            # ROIì—ì„œ ê²€ì¶œ ì‹¤íŒ¨ ì‹œ ì „ì²´ í”„ë ˆì„ ê²€ì¶œ
            if not results or len(results) == 0 or results[0].boxes is None or len(results[0].boxes) == 0:
                self.roi_fail_count += 1
                if self.roi_fail_count >= self.max_roi_fail:
                    results = self._detect_full_frame(processed_frame)
                    roi_offset = (0, 0)
                    self.roi_fail_count = 0
            else:
                self.roi_fail_count = 0
        else:
            # ROI ì—†ìœ¼ë©´ ì „ì²´ í”„ë ˆì„ ê²€ì¶œ
            results = self._detect_full_frame(processed_frame)
            roi_offset = (0, 0)
        
        # ì¶”ë¡  ì‹œê°„ ì¸¡ì • ì¢…ë£Œ
        inference_time = (time.time() - start_time) * 1000  # ms
        self.inference_times.append(inference_time)
        if len(self.inference_times) > 30:
            self.inference_times.pop(0)
        self.avg_inference_time = sum(self.inference_times) / len(self.inference_times)
        
        # ê²°ê³¼ ì²˜ë¦¬
        faces_msg = Float32MultiArray()
        faces_data = []
        num_faces = 0
        best_detection = None
        max_area = 0
        best_conf = 0
        
        # ROI ì˜¤í”„ì…‹ ì ìš©
        offset_x, offset_y = roi_offset
        
        if results and len(results) > 0:
            boxes = results[0].boxes
            
            if boxes is not None and len(boxes) > 0:
                for box in boxes:
                    # clone()ìœ¼ë¡œ ë³µì‚¬ í›„ ì˜¤í”„ì…‹ ì ìš©
                    coords = box.xyxy[0].cpu().numpy().copy()
                    x1 = coords[0] + offset_x
                    y1 = coords[1] + offset_y
                    x2 = coords[2] + offset_x
                    y2 = coords[3] + offset_y
                    conf = float(box.conf[0].cpu().numpy())
                    area = (x2 - x1) * (y2 - y1)
                    
                    if area > max_area:
                        max_area = area
                        best_conf = conf
                        best_detection = {
                            'x1': int(x1), 'y1': int(y1),
                            'x2': int(x2), 'y2': int(y2),
                            'conf': conf
                        }
        
        # ê¹œë¹¡ì„ ë°©ì§€
        if best_detection is None:
            self.no_detection_count += 1
            if self.last_detection is not None and self.no_detection_count <= self.max_no_detection:
                best_detection = self.last_detection.copy()
                best_detection['conf'] = self.last_detection['conf'] * (0.9 ** self.no_detection_count)
        else:
            self.no_detection_count = 0
            self.last_detection = best_detection
            self.last_roi = (best_detection['x1'], best_detection['y1'],
                            best_detection['x2'], best_detection['y2'])
        
        # ê²€ì¶œ ê²°ê³¼ ì²˜ë¦¬
        if best_detection:
            num_faces = 1
            x1 = best_detection['x1']
            y1 = best_detection['y1']
            x2 = best_detection['x2']
            y2 = best_detection['y2']
            
            width = x2 - x1
            height = y2 - y1
            center_x = x1 + width // 2
            center_y = y1 + height // 2
            
            # Bounding box ê·¸ë¦¬ê¸°
            color = (0, 255, 0) if self.no_detection_count == 0 else (0, 255, 255)
            cv2.rectangle(frame, (x1, y1), (x2, y2), color, 2)
            cv2.circle(frame, (center_x, center_y), 5, (0, 0, 255), -1)
            
            # ROI ì˜ì—­ í‘œì‹œ (ë””ë²„ê·¸ìš©)
            if roi is not None:
                cv2.rectangle(frame, (roi[0], roi[1]), (roi[2], roi[3]), (255, 0, 255), 1)
            
            # ì‹ ë¢°ë„ í‘œì‹œ
            raw_confidence = best_detection['conf']
            self.confidence_history.append(raw_confidence)
            if len(self.confidence_history) > self.history_size:
                self.confidence_history.pop(0)
            
            smoothed_confidence = sum(self.confidence_history) / len(self.confidence_history)
            
            cv2.putText(frame, f"Conf: {smoothed_confidence:.2f}", 
                       (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            # ì¢Œí‘œ ë°ì´í„°
            faces_data.extend([float(center_x), float(center_y), 
                             float(width), float(height)])
        
        # FPS ê³„ì‚°
        self.frame_count += 1
        current_time = self.get_clock().now()
        time_diff = (current_time - self.last_fps_time).nanoseconds / 1e9
        
        if time_diff >= 1.0:
            self.fps = self.frame_count / time_diff
            self.frame_count = 0
            self.last_fps_time = current_time
        
        # ì •ë³´ í‘œì‹œ
        cv2.putText(frame, f"Faces: {num_faces}", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)
        cv2.putText(frame, f"FPS: {self.fps:.1f}", (10, 70), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)
        cv2.putText(frame, f"Inference: {self.avg_inference_time:.1f}ms", (10, 110), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (255, 0, 0), 2)
        
        # ìµœì í™” ìƒíƒœ í‘œì‹œ
        opt_status = []
        if self.use_tensorrt and self.cuda_available:
            opt_status.append("TRT")
        if self.use_fp16 and self.cuda_available:
            opt_status.append("FP16")
        if self.use_roi_tracking:
            opt_status.append("ROI")
        
        opt_text = f"YOLOv8 Optimized [{', '.join(opt_status)}]"
        cv2.putText(frame, opt_text, (10, 150), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 255), 2)
        
        # ì´ë¯¸ì§€ í¼ë¸”ë¦¬ì‹œ
        try:
            img_msg = self.bridge.cv2_to_imgmsg(frame, "bgr8")
            self.image_pub.publish(img_msg)
        except Exception as e:
            self.get_logger().error(f"ì´ë¯¸ì§€ ë°œí–‰ ì‹¤íŒ¨: {e}")
        
        # ì¢Œí‘œ í¼ë¸”ë¦¬ì‹œ
        faces_msg.data = faces_data
        self.faces_pub.publish(faces_msg)
        
        # OpenCV ì°½ í‘œì‹œ
        if self.show_window:
            cv2.imshow("Face Detection (YOLOv8 Optimized)", frame)
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q') or key == 27:
                self.get_logger().info("ì¢…ë£Œí•©ë‹ˆë‹¤.")
                cv2.destroyAllWindows()
                rclpy.shutdown()


def main(args=None):
    rclpy.init(args=args)
    node = FaceDetectionYoloOptimizedNode()
    
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        cv2.destroyAllWindows()
        node.destroy_node()
        if rclpy.ok():
            rclpy.shutdown()


if __name__ == "__main__":
    main()
