#!/usr/bin/env python3
"""
Face Detection Node - RealSense ì¹´ë©”ë¼ë¡œ ì–¼êµ´ ê°ì§€

MediaPipe Face Detectionì„ ì‚¬ìš©í•˜ì—¬ ì–¼êµ´ ê°ì§€ í›„ ì¢Œí‘œ í¼ë¸”ë¦¬ì‹œ
- 468ê°œ ì–¼êµ´ ëœë“œë§ˆí¬ ì¶”ì¶œ
- 60+ FPS ì„±ëŠ¥
- ì •í™•ë„ 90%+

Subscribed Topics:
  /camera/camera/color/image_raw - RealSense ì»¬ëŸ¬ ì´ë¯¸ì§€

Published Topics:
  /face_detection/image - ì–¼êµ´ í‘œì‹œëœ ì´ë¯¸ì§€ (RViz í™•ì¸ìš©)
  /face_detection/faces - ì–¼êµ´ ì¢Œí‘œ ë¦¬ìŠ¤íŠ¸ [center_x, center_y, w, h, ...]
"""
import cv2
import numpy as np
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image
from std_msgs.msg import Float32MultiArray
from cv_bridge import CvBridge
import mediapipe as mp


class FaceDetectionNode(Node):
    def __init__(self):
        super().__init__('face_detection_node')
        
        self.bridge = CvBridge()
        self.current_frame = None
        
        # íŒŒë¼ë¯¸í„° ì„ ì–¸
        self.declare_parameter('model_selection', 1)  # 0=ê·¼ê±°ë¦¬(2m), 1=ì›ê±°ë¦¬(5m)
        self.declare_parameter('min_detection_confidence', 0.5)
        self.declare_parameter('show_window', True)
        self.declare_parameter('draw_landmarks', False)  # 468ê°œ ëœë“œë§ˆí¬ í‘œì‹œ ì—¬ë¶€
        
        model_selection = self.get_parameter('model_selection').value
        min_confidence = self.get_parameter('min_detection_confidence').value
        self.show_window = self.get_parameter('show_window').value
        self.draw_landmarks = self.get_parameter('draw_landmarks').value
        
        # MediaPipe Face Detection ì´ˆê¸°í™”
        self.mp_face_detection = mp.solutions.face_detection
        self.mp_drawing = mp.solutions.drawing_utils
        
        self.face_detection = self.mp_face_detection.FaceDetection(
            model_selection=model_selection,
            min_detection_confidence=min_confidence
        )
        
        # ì„±ëŠ¥ ì¸¡ì •ìš©
        self.frame_count = 0
        self.fps = 0.0
        self.last_fps_time = self.get_clock().now()
        
        # ì‹œê°„ì  í•„í„°ë§ (ì‹ ë¢°ë„ í–¥ìƒ)
        self.confidence_history = []
        self.history_size = 5  # ìµœê·¼ 5í”„ë ˆì„ í‰ê· 
        
        # RealSense ì´ë¯¸ì§€ í† í”½ êµ¬ë…
        self.image_sub = self.create_subscription(
            Image,
            '/camera/camera/color/image_raw',
            self.image_callback,
            10
        )
        
        # í¼ë¸”ë¦¬ì…”: ì–¼êµ´ í‘œì‹œëœ ì´ë¯¸ì§€
        self.image_pub = self.create_publisher(
            Image,
            '/face_detection/image',
            10
        )
        
        # í¼ë¸”ë¦¬ì…”: ì–¼êµ´ ì¢Œí‘œ
        self.faces_pub = self.create_publisher(
            Float32MultiArray,
            '/face_detection/faces',
            10
        )
        
        # íƒ€ì´ë¨¸ë¡œ ì²˜ë¦¬ (30Hz)
        self.timer = self.create_timer(0.033, self.process_loop)
        
        self.get_logger().info("=" * 50)
        self.get_logger().info("ğŸ¥ Face Detection Node (MediaPipe) ì‹œì‘!")
        self.get_logger().info(f"  Model: {'Long-range (5m)' if model_selection == 1 else 'Short-range (2m)'}")
        self.get_logger().info(f"  Confidence: {min_confidence}")
        self.get_logger().info("  Published Topics:")
        self.get_logger().info("    /face_detection/image")
        self.get_logger().info("    /face_detection/faces")
        self.get_logger().info("=" * 50)
    
    def image_callback(self, msg):
        """ROS2 ì´ë¯¸ì§€ ë©”ì‹œì§€ë¥¼ OpenCV ì´ë¯¸ì§€ë¡œ ë³€í™˜"""
        try:
            self.current_frame = self.bridge.imgmsg_to_cv2(msg, "bgr8")
        except Exception as e:
            self.get_logger().error(f"ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}")
    
    def process_loop(self):
        """ì–¼êµ´ ê°ì§€ ë° í¼ë¸”ë¦¬ì‹œ (MediaPipe)"""
        if self.current_frame is None:
            return
        
        frame = self.current_frame.copy()
        h, w, _ = frame.shape
        
        # MediaPipeëŠ” RGB ì…ë ¥ í•„ìš”
        rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
        
        # MediaPipe ì–¼êµ´ ê°ì§€
        results = self.face_detection.process(rgb_frame)
        
        # ì–¼êµ´ ì¢Œí‘œ ë©”ì‹œì§€ ìƒì„±
        faces_msg = Float32MultiArray()
        faces_data = []
        
        num_faces = 0
        
        if results.detections:
            for detection in results.detections:
                num_faces += 1
                
                # Bounding box ì •ë³´
                bbox = detection.location_data.relative_bounding_box
                
                # í”½ì…€ ì¢Œí‘œë¡œ ë³€í™˜
                x = int(bbox.xmin * w)
                y = int(bbox.ymin * h)
                width = int(bbox.width * w)
                height = int(bbox.height * h)
                
                # ì¤‘ì‹¬ì  ê³„ì‚°
                center_x = x + width // 2
                center_y = y + height // 2
                
                # Bounding box ê·¸ë¦¬ê¸°
                cv2.rectangle(frame, (x, y), (x + width, y + height), (0, 255, 0), 2)
                
                # ì¤‘ì‹¬ì  í‘œì‹œ
                cv2.circle(frame, (center_x, center_y), 5, (0, 0, 255), -1)
                
                # ì‹ ë¢°ë„ ì‹œê°„ì  í•„í„°ë§ (ë¶€ë“œëŸ½ê³  ì•ˆì •ì )
                raw_confidence = detection.score[0]
                self.confidence_history.append(raw_confidence)
                if len(self.confidence_history) > self.history_size:
                    self.confidence_history.pop(0)
                
                # ì´ë™ í‰ê· ìœ¼ë¡œ ë¶€ë“œëŸ¬ìš´ ì‹ ë¢°ë„
                smoothed_confidence = sum(self.confidence_history) / len(self.confidence_history)
                
                # í™”ë©´ í‘œì‹œ (ì›ë³¸ / í•„í„°ë§)
                cv2.putText(frame, f"Raw: {raw_confidence:.2f}", 
                           (x, y - 25), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255, 255, 0), 1)
                cv2.putText(frame, f"Smooth: {smoothed_confidence:.2f}", 
                           (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
                
                # 6ê°œ ëœë“œë§ˆí¬ ê·¸ë¦¬ê¸° (ì˜µì…˜)
                if self.draw_landmarks:
                    # MediaPipeëŠ” 6ê°œ ì£¼ìš” ëœë“œë§ˆí¬ ì œê³µ
                    # (ì˜¤ë¥¸ìª½ ëˆˆ, ì™¼ìª½ ëˆˆ, ì½” ë, ì… ì¤‘ì‹¬, ì˜¤ë¥¸ìª½ ê·€, ì™¼ìª½ ê·€)
                    for keypoint in detection.location_data.relative_keypoints:
                        kp_x = int(keypoint.x * w)
                        kp_y = int(keypoint.y * h)
                        cv2.circle(frame, (kp_x, kp_y), 3, (255, 0, 0), -1)
                
                # ì¢Œí‘œ ë°ì´í„° ì¶”ê°€ [center_x, center_y, width, height]
                faces_data.extend([float(center_x), float(center_y), 
                                 float(width), float(height)])
        
        # FPS ê³„ì‚°
        self.frame_count += 1
        current_time = self.get_clock().now()
        time_diff = (current_time - self.last_fps_time).nanoseconds / 1e9
        
        if time_diff >= 1.0:  # 1ì´ˆë§ˆë‹¤ ì—…ë°ì´íŠ¸
            self.fps = self.frame_count / time_diff
            self.frame_count = 0
            self.last_fps_time = current_time
        
        # ì •ë³´ í‘œì‹œ
        cv2.putText(frame, f"Faces: {num_faces}", (10, 30), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)
        cv2.putText(frame, f"FPS: {self.fps:.1f}", (10, 70), 
                   cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 0, 0), 2)
        cv2.putText(frame, "MediaPipe", (10, 110), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, (0, 255, 255), 2)
        
        # ì´ë¯¸ì§€ í¼ë¸”ë¦¬ì‹œ
        try:
            img_msg = self.bridge.cv2_to_imgmsg(frame, "bgr8")
            self.image_pub.publish(img_msg)
        except Exception as e:
            self.get_logger().error(f"ì´ë¯¸ì§€ ë°œí–‰ ì‹¤íŒ¨: {e}")
        
        # ì¢Œí‘œ í¼ë¸”ë¦¬ì‹œ
        faces_msg.data = faces_data
        self.faces_pub.publish(faces_msg)
        
        # OpenCV ì°½ í‘œì‹œ (ì˜µì…˜)
        if self.show_window:
            cv2.imshow("Face Detection (MediaPipe)", frame)
            key = cv2.waitKey(1) & 0xFF
            if key == ord('q') or key == 27:
                self.get_logger().info("ì¢…ë£Œí•©ë‹ˆë‹¤.")
                cv2.destroyAllWindows()
                rclpy.shutdown()
    
    def __del__(self):
        """ì†Œë©¸ì - MediaPipe ë¦¬ì†ŒìŠ¤ í•´ì œ"""
        if hasattr(self, 'face_detection'):
            self.face_detection.close()


def main(args=None):
    rclpy.init(args=args)
    node = FaceDetectionNode()
    
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        cv2.destroyAllWindows()
        node.destroy_node()
        if rclpy.ok():
            rclpy.shutdown()


if __name__ == "__main__":
    main()
