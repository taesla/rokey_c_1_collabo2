#!/usr/bin/env python3
"""
Face Tracking Node - 2D ì¢Œí‘œë¥¼ 3D ë¡œë´‡ ì¢Œí‘œê³„ë¡œ ë³€í™˜

TF2ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¹´ë©”ë¼ ì¢Œí‘œê³„ â†’ ë¡œë´‡ ë² ì´ìŠ¤ ì¢Œí‘œê³„ ë³€í™˜

Subscribed Topics:
  /face_detection/faces - ì–¼êµ´ 2D ì¢Œí‘œ (from face_detection_node)
  /camera/camera/aligned_depth_to_color/image_raw - ê¹Šì´ ì´ë¯¸ì§€
  /camera/camera/color/camera_info - ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„°

Published Topics:
  /face_tracking/marker - RViz ë§ˆì»¤ (ì¹´ë©”ë¼ í”„ë ˆì„, ì´ˆë¡ìƒ‰)
  /face_tracking/marker_robot - RViz ë§ˆì»¤ (ë¡œë´‡ ë² ì´ìŠ¤ í”„ë ˆì„, ë¹¨ê°„ìƒ‰) â† ë¡œë´‡ ëª©í‘œ ìœ„ì¹˜!
  /face_tracking/line - ì¹´ë©”ë¼â†’ì–¼êµ´ ì—°ê²°ì„  (ë…¸ë€ìƒ‰)
"""
import numpy as np
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image, CameraInfo
from std_msgs.msg import Float32MultiArray
from visualization_msgs.msg import Marker
from geometry_msgs.msg import Point, PointStamped
from cv_bridge import CvBridge
import tf2_ros
import tf2_geometry_msgs


class FaceTrackingNode(Node):
    def __init__(self):
        super().__init__('face_tracking_node')
        
        self.bridge = CvBridge()
        
        # íŒŒë¼ë¯¸í„° ì„ ì–¸
        self.declare_parameter('target_offset_mm', 650.0)
        self.declare_parameter('camera_frame', 'camera_color_optical_frame')
        self.declare_parameter('robot_frame', 'base_link')
        
        self.target_offset_mm = self.get_parameter('target_offset_mm').value
        self.camera_frame = self.get_parameter('camera_frame').value
        self.robot_frame = self.get_parameter('robot_frame').value
        
        # ë°ì´í„° ì €ì¥
        self.faces_data = []
        self.depth_frame = None
        self.intrinsics = None
        
        # TF2 ë²„í¼ ë° ë¦¬ìŠ¤ë„ˆ
        self.tf_buffer = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer, self)
        
        # êµ¬ë…ì
        self.faces_sub = self.create_subscription(
            Float32MultiArray, '/face_detection/faces', self.faces_callback, 10)
        self.depth_sub = self.create_subscription(
            Image, '/camera/camera/aligned_depth_to_color/image_raw', self.depth_callback, 10)
        self.camera_info_sub = self.create_subscription(
            CameraInfo, '/camera/camera/color/camera_info', self.camera_info_callback, 10)
        
        # ë°œí–‰ì
        self.marker_pub = self.create_publisher(Marker, '/face_tracking/marker', 10)
        self.marker_robot_pub = self.create_publisher(Marker, '/face_tracking/marker_robot', 10)
        self.line_pub = self.create_publisher(Marker, '/face_tracking/line', 10)
        
        # íƒ€ì´ë¨¸: íŠ¸ë˜í‚¹ ë£¨í”„ (30Hz) - ë³‘ëª© í•´ê²°
        self.timer = self.create_timer(0.033, self.tracking_loop)
        
        # ì„±ëŠ¥ ì¸¡ì •
        self.loop_count = 0
        self.last_fps_time = self.get_clock().now()
        self.tracking_fps = 0.0
        
        self.get_logger().info("=" * 60)
        self.get_logger().info("ğŸ”„ Face Tracking Node (TF2) ì‹œì‘! [30Hz]")
        self.get_logger().info("  ğŸŸ¢ ì´ˆë¡ ë§ˆì»¤: ì¹´ë©”ë¼ í”„ë ˆì„")
        self.get_logger().info("  ğŸ”´ ë¹¨ê°„ ë§ˆì»¤: ë¡œë´‡ ë² ì´ìŠ¤ í”„ë ˆì„ (ëª©í‘œ)")
        self.get_logger().info("=" * 60)
    
    def faces_callback(self, msg):
        self.faces_data = list(msg.data)
    
    def depth_callback(self, msg):
        try:
            self.depth_frame = self.bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')
        except Exception as e:
            self.get_logger().error(f"ê¹Šì´ ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}")
    
    def camera_info_callback(self, msg):
        self.intrinsics = {
            'fx': msg.k[0], 'fy': msg.k[4],
            'ppx': msg.k[2], 'ppy': msg.k[5]
        }
    
    def get_3d_position(self, center_x, center_y):
        """2D í”½ì…€ ì¢Œí‘œ â†’ 3D ì¹´ë©”ë¼ ì¢Œí‘œ (mm)"""
        if self.depth_frame is None or self.intrinsics is None:
            return None
        
        x, y = int(center_x), int(center_y)
        h, w = self.depth_frame.shape
        
        if x < 5 or x >= w - 5 or y < 5 or y >= h - 5:
            return None
        
        # ìµœì í™”: 5x5 ì˜ì—­ì—ì„œ median ëŒ€ì‹  ì¤‘ì‹¬ 3x3ë§Œ ì‚¬ìš©
        depth_region = self.depth_frame[y-1:y+2, x-1:x+2]
        valid_depths = depth_region[depth_region > 0]
        
        if len(valid_depths) == 0:
            return None
        
        # ê°œì„ : Trimmed Mean (ìƒí•˜ìœ„ 20% ì œê±° í›„ í‰ê· )
        # medianë³´ë‹¤ ë¹ ë¥´ë©´ì„œë„ ì´ìƒì¹˜ì— ê°•ê±´
        if len(valid_depths) >= 5:
            valid_depths_sorted = np.sort(valid_depths)
            trim_count = max(1, len(valid_depths) // 5)  # 20% ì œê±°
            trimmed = valid_depths_sorted[trim_count:-trim_count]
            depth_mm = float(np.mean(trimmed))
        else:
            # ìƒ˜í”Œ ì ìœ¼ë©´ ê·¸ëƒ¥ mean
            depth_mm = float(np.mean(valid_depths))
        
        camera_x = (center_x - self.intrinsics['ppx']) * depth_mm / self.intrinsics['fx']
        camera_y = (center_y - self.intrinsics['ppy']) * depth_mm / self.intrinsics['fy']
        camera_z = depth_mm
        
        return np.array([camera_x, camera_y, camera_z])
    
    def camera_to_robot_tf2(self, camera_pos_mm):
        """TF2ë¥¼ ì‚¬ìš©í•´ ì¹´ë©”ë¼ ì¢Œí‘œ â†’ ë¡œë´‡ ë² ì´ìŠ¤ ì¢Œí‘œ ë³€í™˜"""
        try:
            point_camera = PointStamped()
            point_camera.header.frame_id = self.camera_frame
            point_camera.header.stamp = self.get_clock().now().to_msg()
            point_camera.point.x = camera_pos_mm[0] / 1000.0
            point_camera.point.y = camera_pos_mm[1] / 1000.0
            point_camera.point.z = camera_pos_mm[2] / 1000.0
            
            # ìµœì í™”: íƒ€ì„ì•„ì›ƒ ë‹¨ì¶• (0.1ì´ˆ â†’ 0.01ì´ˆ)
            transform = self.tf_buffer.lookup_transform(
                self.robot_frame, self.camera_frame,
                rclpy.time.Time(),
                timeout=rclpy.duration.Duration(seconds=0.01)
            )
            
            point_base = tf2_geometry_msgs.do_transform_point(point_camera, transform)
            
            return np.array([
                point_base.point.x * 1000.0,
                point_base.point.y * 1000.0,
                point_base.point.z * 1000.0
            ])
            
        except (tf2_ros.LookupException, tf2_ros.ConnectivityException, 
                tf2_ros.ExtrapolationException) as e:
            self.get_logger().warn(f"TF2 ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None
    
    def publish_camera_marker(self, camera_pos):
        """ì¹´ë©”ë¼ í”„ë ˆì„ ë§ˆì»¤ (ì´ˆë¡ìƒ‰)"""
        marker = Marker()
        marker.header.frame_id = self.camera_frame
        marker.header.stamp = self.get_clock().now().to_msg()
        marker.ns = "face_camera"
        marker.id = 0
        marker.type = Marker.SPHERE
        marker.action = Marker.ADD
        marker.pose.position.x = camera_pos[0] / 1000.0
        marker.pose.position.y = camera_pos[1] / 1000.0
        marker.pose.position.z = camera_pos[2] / 1000.0
        marker.pose.orientation.w = 1.0
        marker.scale.x = marker.scale.y = marker.scale.z = 0.15
        marker.color.r, marker.color.g, marker.color.b, marker.color.a = 0.0, 1.0, 0.0, 0.8
        marker.lifetime.nanosec = 500000000
        self.marker_pub.publish(marker)
    
    def publish_robot_marker(self, robot_pos):
        """ë¡œë´‡ ë² ì´ìŠ¤ í”„ë ˆì„ ë§ˆì»¤ (ë¹¨ê°„ìƒ‰)"""
        marker = Marker()
        marker.header.frame_id = self.robot_frame
        marker.header.stamp = self.get_clock().now().to_msg()
        marker.ns = "face_robot_target"
        marker.id = 1
        marker.type = Marker.SPHERE
        marker.action = Marker.ADD
        marker.pose.position.x = robot_pos[0] / 1000.0
        marker.pose.position.y = robot_pos[1] / 1000.0
        marker.pose.position.z = robot_pos[2] / 1000.0
        marker.pose.orientation.w = 1.0
        marker.scale.x = marker.scale.y = marker.scale.z = 0.20
        marker.color.r, marker.color.g, marker.color.b, marker.color.a = 1.0, 0.0, 0.0, 0.6
        marker.lifetime.nanosec = 500000000
        self.marker_robot_pub.publish(marker)
    
    def publish_line_marker(self, camera_pos):
        """ì¹´ë©”ë¼â†’ì–¼êµ´ ë¼ì¸ (ë…¸ë€ìƒ‰)"""
        marker = Marker()
        marker.header.frame_id = self.camera_frame
        marker.header.stamp = self.get_clock().now().to_msg()
        marker.ns = "face_line"
        marker.id = 2
        marker.type = Marker.LINE_STRIP
        marker.action = Marker.ADD
        
        p1 = Point()
        p2 = Point()
        p2.x, p2.y, p2.z = camera_pos[0]/1000.0, camera_pos[1]/1000.0, camera_pos[2]/1000.0
        marker.points = [p1, p2]
        
        marker.scale.x = 0.01
        marker.color.r, marker.color.g, marker.color.b, marker.color.a = 1.0, 1.0, 0.0, 1.0
        marker.lifetime.nanosec = 500000000
        self.line_pub.publish(marker)
    
    def tracking_loop(self):
        """ë©”ì¸ íŠ¸ë˜í‚¹ ë£¨í”„ (30Hz)"""
        # FPS ì¸¡ì •
        self.loop_count += 1
        current_time = self.get_clock().now()
        time_diff = (current_time - self.last_fps_time).nanoseconds / 1e9
        
        if time_diff >= 1.0:
            self.tracking_fps = self.loop_count / time_diff
            self.loop_count = 0
            self.last_fps_time = current_time
            self.get_logger().info(f"ğŸ“Š Tracking FPS: {self.tracking_fps:.1f}")
        
        if len(self.faces_data) < 4:
            return
        
        center_x, center_y = self.faces_data[0], self.faces_data[1]
        
        camera_pos = self.get_3d_position(center_x, center_y)
        if camera_pos is None:
            return
        
        self.publish_camera_marker(camera_pos)
        self.publish_line_marker(camera_pos)
        
        # ëª©í‘œ ìœ„ì¹˜ ê³„ì‚° (ì–¼êµ´ì—ì„œ offsetë§Œí¼ ë–¨ì–´ì§„ ìœ„ì¹˜)
        distance = np.linalg.norm(camera_pos)
        if distance < 1.0:
            return
        
        direction = camera_pos / distance
        target_camera_pos = camera_pos - direction * self.target_offset_mm
        
        robot_pos = self.camera_to_robot_tf2(target_camera_pos)
        if robot_pos is None:
            return
        
        self.publish_robot_marker(robot_pos)


def main(args=None):
    rclpy.init(args=args)
    node = FaceTrackingNode()
    
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        if rclpy.ok():
            rclpy.shutdown()


if __name__ == "__main__":
    main()
