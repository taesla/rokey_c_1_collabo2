{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O-LcsDMko8zr"
      },
      "source": [
        "## GPU and CPU\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D-rMjxEqo-Li"
      },
      "source": [
        "딥러닝 모델은 수많은 파라미터와 복잡한 연산을 포함하고 있기 때문에, 이를 처리하는 데 막대한 연산 자원이 요구됩니다. 특히 딥러닝의 핵심 작업인 **행렬 연산(Matrix Operations)**은 매우 방대한 양의 데이터를 동시에 처리해야 하는데, 이러한 작업을 효율적으로 처리하기 위해 병렬 연산의 개념이 필수적입니다.\n",
        "\n",
        "GPU는 수천 개 이상의 코어를 통해 수많은 연산을 동시에 처리할 수 있는 병렬 처리 능력을 가지고 있어, 딥러닝 모델 학습 시 CPU에 비해 훨씬 더 빠르게 연산을 수행할 수 있습니다. 반면 CPU는 소수의 고성능 코어로 순차적인 작업에 강점을 가지지만, 병렬 연산의 효율성은 GPU에 미치지 못합니다.\n",
        "\n",
        "이를 비유하자면, CPU는 그림을 그릴 때 풍선을 하나씩 던져 그림을 완성하는 방식이라면, GPU는 여러 개의 풍선을 동시에 던져 더 빠르게 그림을 완성하는 방식으로 볼 수 있습니다.\n",
        "\n",
        "#### CPU\n",
        "\n",
        "<img src=\"https://user-images.githubusercontent.com/12128784/111595314-595baf80-880f-11eb-9cff-61a90d7d479d.gif\" width=\"470\"/>\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### GPU\n",
        "![CircularWaryGnu-max-14mb](https://user-images.githubusercontent.com/12128784/111595738-c707db80-880f-11eb-9df5-e4f832c79dfe.gif)\n",
        "\n",
        "출처: https://www.youtube.com/watch?v=-P28LKWTzrI\n",
        "\n",
        "\n",
        "GPU의 이러한 특징은 특히 대량의 데이터를 동시에 처리해야 하는 딥러닝 학습에 유리하며, 주로 행렬 곱셈이나 벡터 연산과 같은 대규모 병렬 연산을 최적화하는 데 큰 도움이 됩니다. 실제로 GPU를 사용한 딥러닝 학습은 CPU에 비해 수십 배에서 수백 배 빠른 속도를 자랑합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pHfWes8OvumO"
      },
      "source": [
        "## 데이터 작업하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0V0QHArgvxAk"
      },
      "source": [
        "파이토치(PyTorch)에는 데이터 작업을 위한 기본 요소 두가지인 `torch.utils.data.DataLoader` 와 `torch.utils.data.Dataset`이 있습니다. `Dataset`은 샘플과 정답(label)을 저장하고, `DataLoader` 는 `Dataset` 을 반복 가능한 객체(iterable)로 감싸는 역할을 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GCiAZSLHwBVY"
      },
      "source": [
        "### Fashion Mnist\n",
        "\n",
        "이번 섹션에서는 Fashion MNIST 데이터를 활용하여 데이터 처리와 분류 작업을 실습해보겠습니다. Fashion MNIST는 머신러닝 및 딥러닝 모델 학습을 위한 대표적인 데이터셋 중 하나로, 10가지 종류의 의류 이미지로 구성되어 있습니다. 이 데이터는 28x28 픽셀 크기의 흑백 이미지로 되어 있으며, 각 이미지에는 해당하는 의류의 레이블(label)이 포함되어 있습니다.\n",
        "\n",
        "이 데이터는 티셔츠, 바지, 신발 등과 같은 의류 품목이 포함되어 있어, 현실 세계의 패션 이미지를 기반으로 한 분류 작업에 적합합니다. Fashion MNIST의 10개 클래스는 다음과 같이 구성되어 있습니다:\n",
        "\n",
        "1. 티셔츠/탑 (T-shirt/top)\n",
        "2. 바지 (Trouser)\n",
        "3. 풀오버 (Pullover)\n",
        "4. 드레스 (Dress)\n",
        "5. 코트 (Coat)\n",
        "6. 샌들 (Sandal)\n",
        "7. 셔츠 (Shirt)\n",
        "8. 스니커즈 (Sneaker)\n",
        "9. 가방 (Bag)\n",
        "10. 앵클 부츠 (Ankle boot)\n",
        "\n",
        "Fashion MNIST 데이터는 모델의 성능을 평가하거나 딥러닝 모델의 구조를 실험할 때 많이 사용되며, 다양한 신경망 구조를 적용해보고 그 성능을 비교하는 데 적합한 데이터셋입니다.\n",
        "\n",
        "아래 그림은 Fashion MNIST 데이터의 몇 가지 예시를 보여줍니다. 각 클래스는 고유한 의류 품목을 나타내며, 이미지 데이터를 기반으로 모델이 올바르게 분류할 수 있도록 학습하는 것이 목표입니다.\n",
        "\n",
        "\n",
        "![image](https://www.tensorflow.org/tutorials/keras/classification_files/output_oZTImqg_CaW1_0.png?hl=ko)\n",
        "\n",
        "출처:https://www.tensorflow.org/tutorials/keras/classification?hl=ko"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jdofuIblo5PL"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor, Lambda, Compose\n",
        "\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "izj4hiCFpgDq",
        "outputId": "ba5b8c5d-0d46-40af-83fd-aabd0ca26e08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yfEupR-Xv1YO",
        "outputId": "3a62870b-47c8-4b6c-bf81-675544d86ff7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26.4M/26.4M [00:01<00:00, 14.4MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29.5k/29.5k [00:00<00:00, 209kB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4.42M/4.42M [00:01<00:00, 3.93MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5.15k/5.15k [00:00<00:00, 12.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# 공개 데이터셋에서 학습 데이터를 내려받습니다.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\", # dataset 경로 지정\n",
        "    train=True, # True로 선언시 학습 데이터를 가져옴\n",
        "    download=True, # 만일 없을 경우 download를 함\n",
        "    transform=ToTensor(), # tensor 형태로 변환시킴\n",
        ")\n",
        "\n",
        "\n",
        "# 공개 데이터셋에서 테스트 데이터를 내려받습니다.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "training_data[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SrhaiMAwqDbe",
        "outputId": "23580b31-15c3-4e50-a110-14c7d94adb53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[[0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.0000, 0.0510,\n",
              "           0.2863, 0.0000, 0.0000, 0.0039, 0.0157, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0118, 0.0000, 0.1412, 0.5333,\n",
              "           0.4980, 0.2431, 0.2118, 0.0000, 0.0000, 0.0000, 0.0039, 0.0118,\n",
              "           0.0157, 0.0000, 0.0000, 0.0118],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0235, 0.0000, 0.4000, 0.8000,\n",
              "           0.6902, 0.5255, 0.5647, 0.4824, 0.0902, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0471, 0.0392, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.6078, 0.9255,\n",
              "           0.8118, 0.6980, 0.4196, 0.6118, 0.6314, 0.4275, 0.2510, 0.0902,\n",
              "           0.3020, 0.5098, 0.2824, 0.0588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0039, 0.0000, 0.2706, 0.8118, 0.8745,\n",
              "           0.8549, 0.8471, 0.8471, 0.6392, 0.4980, 0.4745, 0.4784, 0.5725,\n",
              "           0.5529, 0.3451, 0.6745, 0.2588],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0039, 0.0039, 0.0000, 0.7843, 0.9098, 0.9098,\n",
              "           0.9137, 0.8980, 0.8745, 0.8745, 0.8431, 0.8353, 0.6431, 0.4980,\n",
              "           0.4824, 0.7686, 0.8980, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7176, 0.8824, 0.8471,\n",
              "           0.8745, 0.8941, 0.9216, 0.8902, 0.8784, 0.8706, 0.8784, 0.8667,\n",
              "           0.8745, 0.9608, 0.6784, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.7569, 0.8941, 0.8549,\n",
              "           0.8353, 0.7765, 0.7059, 0.8314, 0.8235, 0.8275, 0.8353, 0.8745,\n",
              "           0.8627, 0.9529, 0.7922, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0039, 0.0118, 0.0000, 0.0471, 0.8588, 0.8627, 0.8314,\n",
              "           0.8549, 0.7529, 0.6627, 0.8902, 0.8157, 0.8549, 0.8784, 0.8314,\n",
              "           0.8863, 0.7725, 0.8196, 0.2039],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0235, 0.0000, 0.3882, 0.9569, 0.8706, 0.8627,\n",
              "           0.8549, 0.7961, 0.7765, 0.8667, 0.8431, 0.8353, 0.8706, 0.8627,\n",
              "           0.9608, 0.4667, 0.6549, 0.2196],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0157, 0.0000, 0.0000, 0.2157, 0.9255, 0.8941, 0.9020,\n",
              "           0.8941, 0.9412, 0.9098, 0.8353, 0.8549, 0.8745, 0.9176, 0.8510,\n",
              "           0.8510, 0.8196, 0.3608, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0039, 0.0157, 0.0235, 0.0275, 0.0078, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.9294, 0.8863, 0.8510, 0.8745,\n",
              "           0.8706, 0.8588, 0.8706, 0.8667, 0.8471, 0.8745, 0.8980, 0.8431,\n",
              "           0.8549, 1.0000, 0.3020, 0.0000],\n",
              "          [0.0000, 0.0118, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.2431, 0.5686, 0.8000, 0.8941, 0.8118, 0.8353, 0.8667,\n",
              "           0.8549, 0.8157, 0.8275, 0.8549, 0.8784, 0.8745, 0.8588, 0.8431,\n",
              "           0.8784, 0.9569, 0.6235, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0706, 0.1725, 0.3216, 0.4196,\n",
              "           0.7412, 0.8941, 0.8627, 0.8706, 0.8510, 0.8863, 0.7843, 0.8039,\n",
              "           0.8275, 0.9020, 0.8784, 0.9176, 0.6902, 0.7373, 0.9804, 0.9725,\n",
              "           0.9137, 0.9333, 0.8431, 0.0000],\n",
              "          [0.0000, 0.2235, 0.7333, 0.8157, 0.8784, 0.8667, 0.8784, 0.8157,\n",
              "           0.8000, 0.8392, 0.8157, 0.8196, 0.7843, 0.6235, 0.9608, 0.7569,\n",
              "           0.8078, 0.8745, 1.0000, 1.0000, 0.8667, 0.9176, 0.8667, 0.8275,\n",
              "           0.8627, 0.9098, 0.9647, 0.0000],\n",
              "          [0.0118, 0.7922, 0.8941, 0.8784, 0.8667, 0.8275, 0.8275, 0.8392,\n",
              "           0.8039, 0.8039, 0.8039, 0.8627, 0.9412, 0.3137, 0.5882, 1.0000,\n",
              "           0.8980, 0.8667, 0.7373, 0.6039, 0.7490, 0.8235, 0.8000, 0.8196,\n",
              "           0.8706, 0.8941, 0.8824, 0.0000],\n",
              "          [0.3843, 0.9137, 0.7765, 0.8235, 0.8706, 0.8980, 0.8980, 0.9176,\n",
              "           0.9765, 0.8627, 0.7608, 0.8431, 0.8510, 0.9451, 0.2549, 0.2863,\n",
              "           0.4157, 0.4588, 0.6588, 0.8588, 0.8667, 0.8431, 0.8510, 0.8745,\n",
              "           0.8745, 0.8784, 0.8980, 0.1137],\n",
              "          [0.2941, 0.8000, 0.8314, 0.8000, 0.7569, 0.8039, 0.8275, 0.8824,\n",
              "           0.8471, 0.7255, 0.7725, 0.8078, 0.7765, 0.8353, 0.9412, 0.7647,\n",
              "           0.8902, 0.9608, 0.9373, 0.8745, 0.8549, 0.8314, 0.8196, 0.8706,\n",
              "           0.8627, 0.8667, 0.9020, 0.2627],\n",
              "          [0.1882, 0.7961, 0.7176, 0.7608, 0.8353, 0.7725, 0.7255, 0.7451,\n",
              "           0.7608, 0.7529, 0.7922, 0.8392, 0.8588, 0.8667, 0.8627, 0.9255,\n",
              "           0.8824, 0.8471, 0.7804, 0.8078, 0.7294, 0.7098, 0.6941, 0.6745,\n",
              "           0.7098, 0.8039, 0.8078, 0.4510],\n",
              "          [0.0000, 0.4784, 0.8588, 0.7569, 0.7020, 0.6706, 0.7176, 0.7686,\n",
              "           0.8000, 0.8235, 0.8353, 0.8118, 0.8275, 0.8235, 0.7843, 0.7686,\n",
              "           0.7608, 0.7490, 0.7647, 0.7490, 0.7765, 0.7529, 0.6902, 0.6118,\n",
              "           0.6549, 0.6941, 0.8235, 0.3608],\n",
              "          [0.0000, 0.0000, 0.2902, 0.7412, 0.8314, 0.7490, 0.6863, 0.6745,\n",
              "           0.6863, 0.7098, 0.7255, 0.7373, 0.7412, 0.7373, 0.7569, 0.7765,\n",
              "           0.8000, 0.8196, 0.8235, 0.8235, 0.8275, 0.7373, 0.7373, 0.7608,\n",
              "           0.7529, 0.8471, 0.6667, 0.0000],\n",
              "          [0.0078, 0.0000, 0.0000, 0.0000, 0.2588, 0.7843, 0.8706, 0.9294,\n",
              "           0.9373, 0.9490, 0.9647, 0.9529, 0.9569, 0.8667, 0.8627, 0.7569,\n",
              "           0.7490, 0.7020, 0.7137, 0.7137, 0.7098, 0.6902, 0.6510, 0.6588,\n",
              "           0.3882, 0.2275, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.1569,\n",
              "           0.2392, 0.1725, 0.2824, 0.1608, 0.1373, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000],\n",
              "          [0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
              "           0.0000, 0.0000, 0.0000, 0.0000]]]),\n",
              " 9)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lS7jZX-4wHhF"
      },
      "source": [
        "``Dataset`` 을 ``DataLoader`` 의 인자로 전달합니다. 이는 데이터셋을 반복 가능한 객체(iterable)로 감싸고, 자동화된 배치(batch), 샘플링(sampling),\n",
        "섞기(shuffle) 및 다증 프로세스로 데이터 불러오기(multiprocess data loading)를 지원합니다. 여기서는 배치 크기(batch size)를 64로 정의합니다.\n",
        "즉, 데이터로더(dataloader) 객체의 각 요소는 64개의 특징(feature)과 정답(label)을 묶음(batch)으로 반환합니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mwVDsmqzwGXl",
        "outputId": "fd8e934c-7d37-47d6-bec4-64f3d53e9007"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]:  torch.Size([64, 1, 28, 28])\n",
            "Shape of y:  torch.Size([64]) torch.int64\n"
          ]
        }
      ],
      "source": [
        "batch_size = 64\n",
        "\n",
        "# 데이터로더를 생성합니다.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size) # training_data를 batch_size크기로 dataloader에 올립니다.\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(\"Shape of X [N, C, H, W]: \", X.shape)\n",
        "    print(\"Shape of y: \", y.shape, y.dtype)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RdSBc5KWwMoS"
      },
      "source": [
        "## 모델 만들기(Fully Connected layer)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P5bhPu7FwSfE"
      },
      "source": [
        "PyTorch에서 신경망 모델은 `nn.Module`_ 을 상속받는 클래스(class)를 생성하여 정의합니다. `__init__` 함수에서 신경망의 계층(layer)들을 정의하고, `forward` 함수에서는 데이터가 신경망을 통과하는 방식을 결정합니다(즉 신경망의 구조를 결정합니다). `forward`함수는 데이터가 각 계층을 거치며 수행되는 연산을 정의하는 곳으로, 모델의 순전파(forward propagation)가 이 함수에서 이루어집니다.\n",
        "\n",
        "\n",
        "이번 섹션에서는 `fully-connected layer`를 사용한 신경망 모델을 실습해 보겠습니다. `Fully-connected layer`는 각 노드가 이전 계층의 모든 노드와 연결되어 있으며, 이로 인해 각 입력 데이터가 모든 가중치(weight)와 연산되는 구조를 가집니다. 이는 신경망의 기본적인 구조 중 하나로, 입력 데이터를 저차원에서 고차원으로 변환하거나 고차원에서 저차원으로 변환하하는 데 주로 사용됩니다.\n",
        "\n",
        "Fully-connected layer의 작동 방식은 다음과 같습니다:\n",
        "\n",
        "1. 각 입력 노드는 이전 계층의 모든 노드와 연결됩니다.\n",
        "2. 이 연결에서 가중치가 곱해진 후, 각 노드에서 합산되고 활성화 함수(Activation Function)가 적용됩니다.\n",
        "3. 이를 통해 출력값이 계산됩니다.\n",
        "\n",
        "이를 그림으로 나타내면 다음과 같습니다.\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/12128784/140010649-40dce697-5e93-4b64-ab3a-3c547c932ad1.png)\n",
        "\n",
        "위 그림에서 볼 수 있듯이, 각 노드가 이전 층의 모든 노드와 연결되어 있는 구조입니다. 이 방식은 데이터의 특성을 학습하는 데 매우 유용하지만, 입력 데이터의 크기가 커질수록 계산량이 급격히 증가할 수 있습니다. 이와 같이 fully-connected layer는 모델의 파라미터 수가 많아질 수 있으므로, 과적합(overfitting) 방지를 위해 정규화(regularization) 기법을 함께 사용하기도 합니다.\n",
        "\n",
        "\n",
        "\n",
        "Fully-connected layer는 일반적으로 **다층 퍼셉트론(Multilayer Perceptron, MLP)**에서 자주 사용되며, 다음과 같은 그림으로 나타낼 수 있습니다:\n",
        "\n",
        "<img src=\"https://user-images.githubusercontent.com/12128784/111853348-004e6180-895e-11eb-9fd9-8ebfca052b0a.png\" width=\"1000\">\n",
        "\n",
        "위와 같은 MLP는 아래와 같은 방식으로 구현할 수 있습니다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEp0R8AlwLQQ",
        "outputId": "fef8ab71-0680-4092-a89f-954f255b1cd8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n",
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# 학습에 사용할 CPU나 GPU 장치를 얻습니다.\n",
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "print(\"Using {} device\".format(device))\n",
        "\n",
        "# 모델을 정의합니다.\n",
        "class NeuralNetwork(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(NeuralNetwork, self).__init__()\n",
        "\n",
        "        self.flatten = nn.Flatten()  # 행렬을 1자로 쭉 핀것.\n",
        "\n",
        "        # 블럭을 하나 만듦.\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512), # 입력 크기는 28*28이고 출력 크기는 512인 linear 신경망을 만듭니다.\n",
        "            nn.ReLU(),             # 비선형 함수인 ReLU를 만듭니다.\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.flatten(x) # 우선 28*28 크기를 갖는 이미지를 1*784의 크기의 벡터로 쭉 핍니다.\n",
        "        logits = self.linear_relu_stack(x) # 앞서 정의했던 linear_relu_stack을 가져와 x를 입력으로 넣어 logit값을 출력으로 가져옵니다.\n",
        "        return logits\n",
        "\n",
        "model = NeuralNetwork().to(device)\n",
        "print(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YH56o-IRwcSz"
      },
      "source": [
        "### 모델 매개변수 최적화하기\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lOju5geDweag"
      },
      "outputs": [],
      "source": [
        "loss_fn = nn.CrossEntropyLoss() # loss 는 cross entropy loss를 사용할 것입니다.\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3) # optimizer로는 SGD를 사용할 것입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QNZtvH-6wmDA"
      },
      "source": [
        "### 모델 학습하기\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kLETS-UzwnQ3"
      },
      "source": [
        "각 학습 단계(training loop)에서 모델은 (배치(batch)로 제공되는) 학습 데이터셋에 대한 예측을 수행하고,\n",
        "예측 오류를 역전파하여 모델의 매개변수를 조정합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2up80z9zwitm"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "\n",
        "    for batch, (X, y) in enumerate(dataloader): # 각 dataloader의 batch마다 연산을 진행합니다.\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # 예측 오류 계산\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # 역전파\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), batch * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CFvvS0mdwuB7",
        "outputId": "941b0cb7-3d43-4394-9c51-5061d7e8317d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.305443  [    0/60000]\n",
            "loss: 2.294017  [ 6400/60000]\n",
            "loss: 2.281286  [12800/60000]\n",
            "loss: 2.273631  [19200/60000]\n",
            "loss: 2.254644  [25600/60000]\n",
            "loss: 2.245872  [32000/60000]\n",
            "loss: 2.243506  [38400/60000]\n",
            "loss: 2.222690  [44800/60000]\n",
            "loss: 2.224702  [51200/60000]\n",
            "loss: 2.193018  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 50.5%, Avg loss: 2.194005 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 2.220545  [    0/60000]\n",
            "loss: 2.191380  [ 6400/60000]\n",
            "loss: 2.159374  [12800/60000]\n",
            "loss: 2.156152  [19200/60000]\n",
            "loss: 2.109333  [25600/60000]\n",
            "loss: 2.105056  [32000/60000]\n",
            "loss: 2.112170  [38400/60000]\n",
            "loss: 2.070621  [44800/60000]\n",
            "loss: 2.083665  [51200/60000]\n",
            "loss: 2.019094  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 50.3%, Avg loss: 2.026026 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 2.089554  [    0/60000]\n",
            "loss: 2.021219  [ 6400/60000]\n",
            "loss: 1.960550  [12800/60000]\n",
            "loss: 1.966727  [19200/60000]\n",
            "loss: 1.888192  [25600/60000]\n",
            "loss: 1.894634  [32000/60000]\n",
            "loss: 1.917292  [38400/60000]\n",
            "loss: 1.858111  [44800/60000]\n",
            "loss: 1.891764  [51200/60000]\n",
            "loss: 1.795411  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 54.8%, Avg loss: 1.815840 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.928672  [    0/60000]\n",
            "loss: 1.821127  [ 6400/60000]\n",
            "loss: 1.743755  [12800/60000]\n",
            "loss: 1.755476  [19200/60000]\n",
            "loss: 1.686588  [25600/60000]\n",
            "loss: 1.701931  [32000/60000]\n",
            "loss: 1.721645  [38400/60000]\n",
            "loss: 1.675833  [44800/60000]\n",
            "loss: 1.715385  [51200/60000]\n",
            "loss: 1.561219  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 58.9%, Avg loss: 1.612035 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.746792  [    0/60000]\n",
            "loss: 1.621002  [ 6400/60000]\n",
            "loss: 1.520538  [12800/60000]\n",
            "loss: 1.558286  [19200/60000]\n",
            "loss: 1.502761  [25600/60000]\n",
            "loss: 1.548191  [32000/60000]\n",
            "loss: 1.543299  [38400/60000]\n",
            "loss: 1.544974  [44800/60000]\n",
            "loss: 1.584524  [51200/60000]\n",
            "loss: 1.385305  [57600/60000]\n",
            "Test Error: \n",
            " Accuracy: 61.1%, Avg loss: 1.463255 \n",
            "\n",
            "Done!\n"
          ]
        }
      ],
      "source": [
        "epochs = 5\n",
        "\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss_fn, optimizer)\n",
        "    test(test_dataloader, model, loss_fn)\n",
        "print(\"Done!\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s-AsFv9ew0tk"
      },
      "source": [
        "### 모델 저장하기\n",
        "\n",
        "모델을 저장하는 일반적인 방법은 (모델의 매개변수들을 포함하여) 내부 상태 사전(internal state dictionary)을\n",
        "직렬화(serialize)하는 것입니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2HaX2I3zwujo",
        "outputId": "438a1f3b-49c1-4074-df73-d43b1c4d570f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saved PyTorch Model State to model.pth\n"
          ]
        }
      ],
      "source": [
        "torch.save(model.state_dict(), \"model.pth\")\n",
        "print(\"Saved PyTorch Model State to model.pth\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Gd5xDAuw86m"
      },
      "source": [
        "### 모델 불러오기\n",
        "\n",
        "모델을 불러오는 과정에는 모델 구조를 다시 만들고 상태 사전을 모델에 불러오는 과정이 포함됩니다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MSZVV929w7zv",
        "outputId": "0969b658-b5f7-4cf9-8605-e5bae590c68e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NeuralNetwork(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (linear_relu_stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (5): ReLU()\n",
            "  )\n",
            ")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-444ed2fae8f7>:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
            "  load_model.load_state_dict(torch.load(\"model.pth\"))\n"
          ]
        }
      ],
      "source": [
        "load_model = NeuralNetwork()\n",
        "load_model.load_state_dict(torch.load(\"model.pth\"))\n",
        "print(load_model)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_model = load_model.to(device)"
      ],
      "metadata": {
        "id": "FCJsTvGcuzjY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test(test_dataloader, load_model, loss_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6KPcoimLuvJV",
        "outputId": "0142794d-fd8e-4432-fb7d-5a500756bf78"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Error: \n",
            " Accuracy: 61.1%, Avg loss: 1.463255 \n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}