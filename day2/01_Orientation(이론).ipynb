{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "enPr8yIwRpEu"
      },
      "source": [
        "### Deep Learning 개론\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-UZaWHToTkc3"
      },
      "source": [
        "Vision의 역사는 굉장히 오래되었습니다. 이 이미지는 \"Evolution's Big Bang\"이라는 제목과 함께 5억 4300만 년 전 지구의 생명체를 보여주고 있습니다. 이 시기는 \"캄브리아기 대폭발\"로 알려진 시기로, 지구 역사에서 생명체의 다양성이 급격히 증가한 시점입니다.\n",
        "\n",
        "이러한 현상이 일어난 이유로 오스트레일리아의 동물학자가 가장 설득력 있는 의견을 내놓았는데, 이 시기에 동물에게 처음 시각이 생겼다라는 주장이었습니다. 동물에게 시각이 주어짐에 따라 동물들이 능동적으로 살게 되었고(포식자와 피식자가 갈리게 됨), 동물들은 생존을 위해 빠르게 진화한 것입니다.\n",
        "\n",
        "이후 시각은 점점 중요한 감각 기관으로 발전하였습니다. 특히 지능이 높은 동물인 인간은 시각을 가장 큰 감각 시스템으로 가지고 있습니다.이후 시각은 점점 중요한 감각 기관으로 발전하였습니다. 특히 지능이 높은 동물인 인간은 시각을 가장 큰 감각 시스템으로 가지고있습니다.\n",
        "\n",
        "![image](https://github.com/user-attachments/assets/70b8e2ba-5644-4636-ba32-82dd36c8343b)\n",
        "\n",
        "출처:https://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture1.pdf\n",
        "\n",
        "이러한 생물학적 진화는 현대 기술, 특히 computer vision의 발전과도 밀접한 관련이 있습니다. Computer vision은 자연에서의 시각 시스템을 모방하려는 시도로 시작되었으며, 머신러닝과 딥러닝의 발전과 함께 이미지를 분석하고 이해하는 기술로 빠르게 발전해 왔습니다.\n",
        "\n",
        "---\n",
        "\n",
        "본 과정에서는 이러한 computer vision에 관련한 주요 task중 하나인 **image classification**에 대해 다루어 보겠습니다.\n",
        "\n",
        "Image classification이란, AI에게 이미지를 보여주고 그 이미지가 무엇을 나타내는지 분류하는 작업입니다. 이는 컴퓨터 비전에서 가장 기본적이면서도 중요한 과업 중 하나로, 다양한 응용 분야에서 사용됩니다.\n",
        "\n",
        "Image classification의 주요 목표는 주어진 이미지를 분석하여 미리 정의된 여러 클래스 중 하나로 정확하게 분류하는 것입니다. 예를 들어, 아래 그림에서 보듯이, AI가 개, 고양이, 자동차 등 여러 객체가 포함된 이미지 데이터셋을 학습한 후, 새로운 이미지가 주어졌을 때 그 이미지가 어떤 카테고리에 속하는지 예측합니다.\n",
        "\n",
        "![image](https://github.com/user-attachments/assets/c145a87e-65bf-45c1-9cc9-6c690f3d4e70)\n",
        "\n",
        "이 과업을 성공적으로 수행하기 위해서는 AI가 이미지 내의 패턴을 인식하고, 이를 통해 해당 이미지가 속하는 클래스를 추정할 수 있어야 합니다.\n",
        "\n",
        "---\n",
        "\n",
        "이러한 작업을 위해 AI는 인공 신경망(Artificial Neural Network, ANN)을 사용합니다. 이름에서 알 수 있듯, Artificial Neural Network는 인간 뇌의 뉴런 네트워크를 모델로 한 구조입니다. 생물학적 뉴런 네트워크와 인공 신경망 사이에는 몇 가지 중요한 유사점이 존재하며, 이는 AI가 데이터를 처리하고 학습하는 방식에 깊이 반영됩니다.\n",
        "\n",
        "Artificial Neural Network는 실제 생물학적 뉴런과 매우 유사한 방식으로 동작합니다. 생물학적 뉴런은 자극을 받아 신호를 처리하고, 다른 뉴런으로 신호를 전달하는 과정을 통해 정보를 학습합니다. 이 학습 과정에서 중요한 역할을 하는 것이 시냅스의 연결 강도입니다. 인간의 뇌에서는 학습이 일어날 때 뉴런 간의 연결 강도가 변화하면서 새로운 정보가 저장되고, 경험을 통해 점차 뇌가 발전하게 됩니다.\n",
        "\n",
        "인공 신경망에서도 비슷한 원리가 적용됩니다. **뉴런(neuron)** 에 해당하는 인공 신경망의 노드는 입력 데이터를 처리하고, 가중치(weight)와 활성화 함수(activation function)를 적용하여 출력 신호를 생성합니다. 이 출력 신호는 다음 레이어로 전달되며, 이 과정에서 **가중치(weight)**가 학습에 따라 조정됩니다. 가중치가 바로 생물학적 신경망에서의 시냅스 연결 강도에 해당하며, 이 값이 학습을 통해 최적화됩니다.\n",
        "\n",
        "더 구체적으로:\n",
        "\n",
        "1. 사람의 뇌: 뉴런이 수많은 연결을 통해 자극을 받아 신호를 처리하고, 이 신호는 연결된 뉴런을 통해 전달됩니다. 각 뉴런 간의 연결 강도는 학습을 통해 변화하며, 이를 통해 뇌가 새로운 정보를 습득합니다.\n",
        "2. Artificial Neural Network: 입력 데이터를 처리하는 노드는 신호를 전달하며, 이 과정에서 가중치가 중요한 역할을 합니다. 학습이 진행됨에 따라 이 가중치들이 업데이트되면서, 네트워크가 주어진 과업을 점점 더 잘 수행할 수 있게 됩니다.\n",
        "\n",
        "다음 그림은 Artificial Neural Network와 사람의 신경망을 비교한 것입니다.\n",
        "\n",
        "![image](https://github.com/user-attachments/assets/55efca42-6f9e-4e55-bbf8-0e6bd1a54fa1)\n",
        "\n",
        "출처:https://towardsdatascience.com/the-differences-between-artificial-and-biological-neural-networks-a8b46db828b7\n",
        "\n",
        "이 두 구조는 매우 유사하지만, 중요한 차이점도 존재합니다. 사람의 뇌는 수십억 개의 뉴런과 그보다 훨씬 많은 시냅스를 포함하며, 각 뉴런은 복잡한 화학적, 전기적 신호를 주고받습니다. 반면에 인공 신경망은 수학적 연산을 통해 정보 처리를 수행하며, 뉴런 간의 연결은 가중치 매개변수를 통해 디지털 방식으로 구현됩니다. 이 점에서 생물학적 신경망의 복잡성을 인공 신경망이 완전히 모사하는 것은 불가능하지만, 이 유사성을 바탕으로 인공 신경망은 다양한 학습과 인지 과업을 성공적으로 수행할 수 있게 되었습니다.\n",
        "\n",
        "결과적으로, 인공 신경망은 생물학적 신경망의 학습 원리를 차용하여 이미지 분류, 음성 인식, 자연어 처리와 같은 복잡한 작업을 수행할 수 있습니다. 이 학습 과정에서 가중치의 변화는 바로 AI 모델이 더 나은 성능을 발휘하게 만드는 핵심 요소입니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6H1XNGHvTtFw"
      },
      "source": [
        "### Fully Connected layer\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dkq1KdzEju_z"
      },
      "source": [
        "Fully Connected Layer는 인공 신경망에서 가장 기본적이면서도 중요한 계층 중 하나이며, 그 구조는 생물학적 신경망을 모방한 것입니다. 아래 그림에서 볼 수 있듯, 왼쪽에 있는 원은 **뉴런(neuron)** 을, 각 원을 연결하는 선은 뉴런 간의 **연결 강도(가중치)** 를 나타냅니다. Fully Connected라는 이름에서 알 수 있듯, 왼쪽의 모든 뉴런이 오른쪽의 모든 뉴런과 완전히 연결되어 있습니다. 이 구조는 정보가 여러 계층을 거치면서 학습을 통해 최적화되는 방식에서 인간의 뇌와 유사한 작동 원리를 보여줍니다.\n",
        "\n",
        "![image](https://user-images.githubusercontent.com/12128784/140010649-40dce697-5e93-4b64-ab3a-3c547c932ad1.png)\n",
        "\n",
        "Fully Connected Layer에서의 학습은 뉴런 간의 연결 강도 조절하면서 이루어집니다. 사람이 학습할 때, 뉴런 간의 연결 강도(시냅스)가 강화되거나 약화되며 지식이 축적됩니다. 이와 유사하게, 인공 신경망에서는 학습 과정 동안 **가중치(weight)**(뉴런들을 이어주고 있는 선에 할당되어 있는 숫자)가 조정됩니다. 이러한 가중치는 뉴런 간의 연결을 나타내며, 학습을 통해 최적의 가중치를 찾아냄으로써 AI 모델이 더 나은 예측을 할 수 있게 됩니다. 초기에는 가중치가 무작위로 설정되지만, 훈련 과정 중 오차 역전파(backpropagation) 알고리즘을 사용해 점진적으로 조정됩니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jjSWXGzjwTS"
      },
      "source": [
        "### Multi Layer perceptron\n",
        "\n",
        "**Multi-Layer Perceptron (MLP)** 는 Fully Connected Layer를 여러 층으로 쌓은 신경망 구조를 의미합니다. Perceptron은 인공 신경망의 가장 기본적인 단위로, 입력 데이터를 받아 가중치와 함께 계산한 후 출력으로 전달하는 역할을 합니다. 이를 여러 층으로 쌓아 올린 구조가 바로 MLP입니다.\n",
        "\n",
        "아래 그림에서 보듯이, 입력층(Input Layer), 은닉층(Hidden Layer), 그리고 출력층(Output Layer)이 차례로 연결되어 있으며, 각 층은 fully connected layer로 이루어져 있습니다.\n",
        "\n",
        "<!-- ![image](https://user-images.githubusercontent.com/12128784/111853348-004e6180-895e-11eb-9fd9-8ebfca052b0a.png){: width=\"300\" height=\"300\"){: .center} -->\n",
        "\n",
        "<img src=\"https://user-images.githubusercontent.com/12128784/111853348-004e6180-895e-11eb-9fd9-8ebfca052b0a.png\" width=\"1000\">\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09B1LrZFeK9J"
      },
      "source": [
        "지금 부터 MLP의 구조에 대해 더 자세히 설명드리겠습니다.\n",
        "\n",
        "이미지를 처리할 때, 사람이 보는 방식과 컴퓨터가 처리하는 방식에는 큰 차이가 있습니다. 사람이 이미지를 직관적으로 색상과 모양으로 인식하는 반면, 컴퓨터는 이미지를 숫자로 처리합니다. 구체적으로, 컴퓨터는 이미지를 픽셀 값으로 인식합니다. 이 값들은 이미지의 각 픽셀에 대응하는 숫자로, 이미지의 밝기나 색상을 나타냅니다.\n",
        "\n",
        "아래 그림에서 확인할 수 있듯, 컴퓨터는 이미지를 **2차원 행렬(숫자 배열)** 로 변환하여 처리합니다. 이미지의 각 픽셀은 0에서 255 사이의 숫자로 변환되며, 이는 해당 픽셀의 밝기 값을 나타냅니다.\n",
        "\n",
        "<img src=\"https://github.com/user-attachments/assets/f0ce59f2-a7ae-4043-b834-28d0586872b0\" width=\"1000\">\n",
        "<!-- ![image](https://github.com/user-attachments/assets/f0ce59f2-a7ae-4043-b834-28d0586872b0) -->\n",
        "\n",
        "이 숫자 배열은 이미지를 직접적으로 표현하는 방법입니다. 하지만 MLP는 기본적으로 1차원 배열의 데이터를 처리하기 때문에, 2차원 이미지 데이터를 **1차원 배열로 펼치는 과정(Flattening)**이 필요합니다. 즉, 이미지를 하나의 벡터로 변환하는 과정이 먼저 이루어집니다.\n",
        "\n",
        "Flattening은 2차원 이미지를 1차원으로 변환하는 과정입니다. 예를 들어, 28x28 크기의 이미지라면, 이를 1차원 벡터로 변환하면 784×1 크기의 벡터가 됩니다. 이 벡터는 이미지의 각 픽셀에 해당하는 숫자들이 순차적으로 나열된 형태로, MLP의 입력층에 주어집니다.\n",
        "\n",
        "Flatten된 1차원 벡터는 여러 개의 fully-connected layer를 통과하며 점차 높은 수준의 특징(feature)을 학습하게 됩니다. 각 층의 뉴런은 이전 층에서 입력된 데이터를 처리한 후, 그 결과를 다음 층으로 전달합니다. 이 과정에서 각 뉴런 간의 가중치는 학습을 통해 조정되며, MLP는 입력 이미지에서 중요한 패턴을 학습하게 됩니다.\n",
        "\n",
        "최종적으로 MLP는 분류하고자 하는 클래스 수와 동일한 크기를 가진 출력 벡터를 생성합니다. 이 벡터는 이미지가 각 클래스에 속할 확률을 나타내는 값으로 구성됩니다. 예를 들어, MNIST 데이터셋에서 숫자 이미지를 분류한다고 가정할 때, 0부터 9까지 총 10개의 클래스가 있으므로 최종 출력 벡터의 크기는 10이 됩니다.\n",
        "\n",
        "**원-핫 벡터(One-Hot Vector)** 는 이와 같이 각 클래스에 해당하는 확률 값을 나타내는 벡터입니다. 예를 들어, 만약 출력 벡터가 `[0.1, 0.05, 0.75, 0.02, 0.03, 0.02, 0.01, 0.01, 0.00, 0.01]`라면, 이 벡터는 해당 이미지가 숫자 3일 확률이 75%로 가장 높다는 것을 의미합니다. 이처럼, 확률이 가장 높은 클래스가 MLP가 예측한 최종 결과가 됩니다.\n",
        "\n",
        "<img src=\"https://github.com/user-attachments/assets/73a3d9f8-2665-4d46-8071-5aba935849e8\" width=\"1000\">\n",
        "\n",
        "출처: 출처: https://www.3blue1brown.com/lessons/backpropagation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FYviVwu_jzY6"
      },
      "source": [
        "### Parameter Update(Backpropagation)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GfHt3GnMj008"
      },
      "source": [
        "다음으로는 MLP가 어떠한 과정을 거치며 **학습** 되는지를 알아보겠습니다.\n",
        "\n",
        "**1. 입력 이미지와 확률 부포 계산** : MLP에 이미지가 입력되면, 네트워크는 해당 이미지가 각 클래스에 속할 확률을 계산하여 원-핫 벡터 형식으로 출력합니다. 이 원-핫 벡터는 MLP가 예측한 각 클래스에 대한 확률 분포를 나타내며, 예측이 정확할수록 정답 레이블과 가까운 분포를 가지게 됩니다.\n",
        "\n",
        "예를 들어, 이미지가 숫자 '3'이라면, 원-핫 벡터는 [0, 0, 0, 1, 0, 0, 0, 0, 0, 0]이 되어야 하지만, MLP가 잘못 예측했다면, [0.1, 0.05, 0.02, 0.5, 0.1, 0.08, 0.05, 0.05, 0.03, 0.02]와 같은 벡터를 출력할 수 있습니다.\n",
        "\n",
        "**2. 오차 계산** : MLP가 예측한 확률 분포와 실제 정답 레이블 간의 차이를 계산하는데, 이 차이를 **오차(또는 손실)** 라고 합니다. 이 손실 값은 주로 **교차 엔트로피 손실 함수(Cross-Entropy Loss)** 와 같은 함수로 수치화됩니다. 손실 함수는 MLP의 예측이 정답과 얼마나 차이가 나는지를 수치적으로 표현한 값입니다.\n",
        "\n",
        "**3. 오차 역전파(Backpropagation)** : 손실 값이 계산된 후, 오차 역전파(Backpropagation) 과정을 통해 네트워크의 가중치가 업데이트됩니다. 역전파는 신경망에서 발생한 오차를 각 레이어로 되돌려보내는 과정입니다. 이 과정에서 각 가중치가 최종 출력에 얼마나 영향을 미쳤는지를 미분값을 통해 알 수 있으며, 이 값을 사용하여 가중치를 업데이트합니다. 구체적으로, 손실 값이 출력층에서부터 시작해 네트워크의 각 가중치에 미치는 영향을 미분을 통해 계산합니다. 큰 미분값을 가진 가중치는 출력에 더 큰 영향을 미쳤다는 의미이고, 따라서 이러한 가중치는 더 크게 조정됩니다.\n",
        "\n",
        "**4. 가중치 업데이트** : 역전파를 통해 각 가중치에 대한 기울기를 계산한 후, 가중치는 경사 하강법(Gradient Descent) 또는 Adam과 같은 최적화 알고리즘을 사용하여 업데이트됩니다.\n",
        "\n",
        "<img src=\"https://user-images.githubusercontent.com/12128784/163274773-24e4385f-ed5c-498b-a1f6-55525c63e48a.png\" width=\"1000\">\n",
        "\n",
        "<img src=\"https://user-images.githubusercontent.com/12128784/129708066-2659df51-5be5-4a8f-98a5-8877a30b1f23.png\" width=\"1000\">\n",
        "\n",
        "출처: http://cs231n.stanford.edu/slides/2021/lecture_4.pdf\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aYo1G6Qdj1-m"
      },
      "source": [
        "### Model Parameter Optimizer\n",
        "\n",
        "**Optimizer(최적화 알고리즘)** 는 딥러닝 모델이 더 나은 예측을 할 수 있도록 가중치(weight)를 조정해주는 도구입니다. 모델이 학습하는 동안, 가중치라는 숫자들이 계속 업데이트되는데, 이 가중치를 어떻게 효율적으로 조정할지를 결정하는 것이 바로 optimizer의 역할입니다.\n",
        "\n",
        "**간단한 비유** : 딥러닝에서 학습하는 과정을 눈을 감고 산을 내려가는 것에 비유할 수 있습니다. 산꼭대기에서 시작하면, 우리는 더 낮은 위치(더 나은 예측)를 찾아야 합니다. 이때 가중치는 우리가 어디에 위치해 있는지를 나타내고, 손실(loss)은 우리가 얼마나 높은 위치(얼마나 잘못된 예측을 하고 있는지)를 나타냅니다. 그리고 optimizer는 앞이 보이지 않는 상황에서 현재 위치 주변을 더듬어 보며, 더 낮은 곳을 찾아가는 역할을 합니다. 때로는 작은 움직임으로 조금씩 더 나은 방향을 찾고, 때로는 크게 이동하여 더 빠르게 방향을 수정하기도 합니다. 가끔은 최저점(최적 해)에 도달하기 위해 잠시 평지나 오르막을 거쳐야 할 때도 있습니다. 즉, 점진적으로 더 낮은 방향을 향해 가며 산을 내려가는 것처럼, 가중치가 조금씩 조정되며 학습이 진행됩니다. 이 과정에서 다양한 최적화 기법이 사용되며, 상황에 맞는 전략을 선택하는 것이 중요합니다.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MhfAVFS6kciP"
      },
      "source": [
        "![image](https://blog.kakaocdn.net/dn/oCqJD/btrdVjyPt6V/wiBf4XnzZkFZkNA0rt4r1K/img.gif)\n",
        "\n",
        "- SGD (Stochastic Gradient Descent, 확률적 경사 하강법): 전체 데이터셋을 사용하여 비용 함수의 기울기를 계산하지 않고, 한 번에 하나 또는 일부의 훈련 샘플을 사용하여 그라디언트를 계산하고 매개 변수를 업데이트\n",
        "- Momentum (모멘텀): 이전 기울기의 일부를 현재 기울기에 반영하여 업데이트\n",
        "- NAG (Nesterov Accelerated Gradient, 네스테로프 가속 경사): 모멘텀의 단점을 보완한 방식. 현재 위치가 아니라 모멘텀을 적용한 위치에서 기울기를 계산하여, 과도한 이동을 방지.\n",
        "- Adagrad (Adaptive Gradient Algorithm): 학습률을 매개변수마다 다르게 조절하는 방법. 업데이트 크기를 기울기 제곱합으로 나누어, 많이 업데이트된 매개변수는 학습률을 줄이고, 적게 업데이트된 매개변수는 학습률을 키우는 방식.\n",
        "- Adadelta: Adagrad의 단점(학습률 감소)을 해결하기 위해 학습률을 따로 설정하지 않음. 최근 기울기의 변화량만을 고려하여 학습률을 동적으로 조절.\n",
        "- RMSprop (Root Mean Square Propagation): Adagrad의 변형으로, 기울기 제곱합을 누적하는 대신 지수 가중 이동 평균을 사용하여 최근 기울기에 가중치를 둠.\n",
        "- Adam: Momentum과 Adaptive Learning Rate를 합친 방식. 과거 기울기의 지수 가중 이동 평균(EMA, Exponential Moving Average)을 사용하여, 급격한 변화에 덜 민감하도록 조절 함. 또한, RMSprop처럼 기울기의 제곱을 지수 가중 이동 평균으로 추적하여, 학습률을 적응적으로 조절.\n",
        "\n",
        "---\n",
        "\n",
        "지수 가중 이동 평균: 최근 데이터일수록 더 높은 가중치를 부여하여 평균을 계산하는 방법. 즉 과거 데이터보다 최근 데이터에 더 큰 영향을 주도록 만든것.\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
