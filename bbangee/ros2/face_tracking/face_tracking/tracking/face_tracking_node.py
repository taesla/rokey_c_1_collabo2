#!/usr/bin/env python3
"""
Face Tracking Node - 2Dâ†’3D ë³€í™˜ ë° EKF í•„í„°ë§

2D ì–¼êµ´ ì¢Œí‘œë¥¼ 3D ë¡œë´‡ ì¢Œí‘œê³„ë¡œ ë³€í™˜í•˜ê³  EKF í•„í„°ë§ ì ìš©

Subscribed Topics:
    /face_detection/faces - ì–¼êµ´ 2D ì¢Œí‘œ [cx, cy, w, h]
    /camera/camera/aligned_depth_to_color/image_raw - ê¹Šì´ ì´ë¯¸ì§€
    /camera/camera/color/camera_info - ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„°

Published Topics:
    /face_tracking/marker - ì¹´ë©”ë¼ í”„ë ˆì„ ë§ˆì»¤ (ì´ˆë¡)
    /face_tracking/marker_robot - ë¡œë´‡ í”„ë ˆì„ ë§ˆì»¤ (ë¹¨ê°•) â† ë¡œë´‡ ëª©í‘œ!
    /face_tracking/marker_ekf - EKF í•„í„°ë§ ë§ˆì»¤ (ì²­ë¡)
"""
import math
import numpy as np
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image, CameraInfo
from std_msgs.msg import Float32MultiArray
from visualization_msgs.msg import Marker
from geometry_msgs.msg import Point, PointStamped
from cv_bridge import CvBridge
import tf2_ros
import tf2_geometry_msgs

from .ekf_filter import EKFFilter
from ..utils.constants import SAFETY_LIMITS, SAFETY_DISTANCE


class FaceTrackingNode(Node):
    """ì–¼êµ´ ì¶”ì  ë…¸ë“œ - 3D ë³€í™˜ ë° EKF í•„í„°ë§"""
    
    def __init__(self):
        super().__init__('face_tracking_node')
        
        self.bridge = CvBridge()
        
        # íŒŒë¼ë¯¸í„°
        self.declare_parameter('target_offset_mm', 650.0)
        self.declare_parameter('camera_frame', 'camera_color_optical_frame')
        self.declare_parameter('robot_frame', 'base_link')
        
        self.target_offset_mm = self.get_parameter('target_offset_mm').value
        self.camera_frame = self.get_parameter('camera_frame').value
        self.robot_frame = self.get_parameter('robot_frame').value
        
        # ë°ì´í„° ì €ì¥
        self.faces_data = []
        self.depth_frame = None
        self.intrinsics = None
        
        # TF2
        self.tf_buffer = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer, self)
        
        # EKF í•„í„° (ì¹´ë©”ë¼ í”„ë ˆì„)
        self.ekf = EKFFilter(dt=0.033, dim=3)
        
        # ìƒíƒœ
        self.face_detected = False
        
        # ì„±ëŠ¥ ì¸¡ì •
        self.loop_count = 0
        self.success_count = 0
        self.last_fps_time = self.get_clock().now()
        
        # êµ¬ë…ì
        self.faces_sub = self.create_subscription(
            Float32MultiArray, '/face_detection/faces', self.faces_callback, 10)
        self.depth_sub = self.create_subscription(
            Image, '/camera/camera/aligned_depth_to_color/image_raw', self.depth_callback, 10)
        self.camera_info_sub = self.create_subscription(
            CameraInfo, '/camera/camera/color/camera_info', self.camera_info_callback, 10)
        
        # ë°œí–‰ì
        self.marker_pub = self.create_publisher(Marker, '/face_tracking/marker', 10)
        self.marker_robot_pub = self.create_publisher(Marker, '/face_tracking/marker_robot', 10)
        self.marker_ekf_pub = self.create_publisher(Marker, '/face_tracking/marker_ekf', 10)
        self.line_pub = self.create_publisher(Marker, '/face_tracking/line', 10)
        # í…ìŠ¤íŠ¸ ë§ˆì»¤ í¼ë¸”ë¦¬ì…” (ì›ë³¸ ì½”ë“œ ë³µì›)
        self.text_pub = self.create_publisher(Marker, '/face_tracking/text', 10)
        self.text_ekf_pub = self.create_publisher(Marker, '/face_tracking/text_ekf', 10)
        self.text_robot_pub = self.create_publisher(Marker, '/face_tracking/text_robot', 10)
        
        # íƒ€ì´ë¨¸ (100Hz)
        self.timer = self.create_timer(0.01, self.tracking_loop)
        
        self._print_startup_info()
    
    def _print_startup_info(self):
        self.get_logger().info("=" * 60)
        self.get_logger().info("ğŸ”„ Face Tracking Node ì‹œì‘! [100Hz]")
        self.get_logger().info("  ğŸŸ¢ ì´ˆë¡ ë§ˆì»¤: Raw ìœ„ì¹˜")
        self.get_logger().info("  ğŸ”µ ì²­ë¡ ë§ˆì»¤: EKF í•„í„°ë§")
        self.get_logger().info("  ğŸ”´ ë¹¨ê°„ ë§ˆì»¤: ë¡œë´‡ ëª©í‘œ")
        self.get_logger().info("=" * 60)
    
    # ========================================
    # ì½œë°±
    # ========================================
    def faces_callback(self, msg):
        self.faces_data = list(msg.data)
    
    def depth_callback(self, msg):
        try:
            self.depth_frame = self.bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')
        except Exception as e:
            self.get_logger().error(f"ê¹Šì´ ë³€í™˜ ì‹¤íŒ¨: {e}")
    
    def camera_info_callback(self, msg):
        self.intrinsics = {
            'fx': msg.k[0], 'fy': msg.k[4],
            'ppx': msg.k[2], 'ppy': msg.k[5]
        }
    
    # ========================================
    # 3D ë³€í™˜
    # ========================================
    def get_3d_position(self, center_x: float, center_y: float) -> np.ndarray:
        """
        2D í”½ì…€ â†’ 3D ì¹´ë©”ë¼ ì¢Œí‘œ (mm)
        
        í•€í™€ ì¹´ë©”ë¼ ëª¨ë¸:
            X = (u - cx) * Z / fx
            Y = (v - cy) * Z / fy
        """
        if self.depth_frame is None or self.intrinsics is None:
            return None
        
        x, y = int(center_x), int(center_y)
        h, w = self.depth_frame.shape
        
        if x < 10 or x >= w - 10 or y < 10 or y >= h - 10:
            return None
        
        # 9x9 ì˜ì—­ Trimmed Mean (ì´ìƒì¹˜ ì œê±°)
        depth_region = self.depth_frame[y-4:y+5, x-4:x+5]
        valid_depths = depth_region[depth_region > 0]
        
        if len(valid_depths) == 0:
            return None
        
        if len(valid_depths) >= 5:
            sorted_depths = np.sort(valid_depths)
            trim = max(1, len(valid_depths) // 5)
            depth_mm = float(np.mean(sorted_depths[trim:-trim]))
        else:
            depth_mm = float(np.mean(valid_depths))
        
        # 3D ë³€í™˜
        camera_x = (center_x - self.intrinsics['ppx']) * depth_mm / self.intrinsics['fx']
        camera_y = (center_y - self.intrinsics['ppy']) * depth_mm / self.intrinsics['fy']
        camera_z = depth_mm
        
        return np.array([camera_x, camera_y, camera_z])
    
    def camera_to_robot(self, camera_pos_mm: np.ndarray) -> np.ndarray:
        """TF2ë¡œ ì¹´ë©”ë¼ â†’ ë¡œë´‡ ì¢Œí‘œ ë³€í™˜"""
        try:
            point_camera = PointStamped()
            point_camera.header.frame_id = self.camera_frame
            point_camera.header.stamp = self.get_clock().now().to_msg()
            point_camera.point.x = camera_pos_mm[0] / 1000.0
            point_camera.point.y = camera_pos_mm[1] / 1000.0
            point_camera.point.z = camera_pos_mm[2] / 1000.0
            
            transform = self.tf_buffer.lookup_transform(
                self.robot_frame, self.camera_frame,
                rclpy.time.Time(),
                timeout=rclpy.duration.Duration(seconds=0.01)
            )
            
            point_base = tf2_geometry_msgs.do_transform_point(point_camera, transform)
            
            return np.array([
                point_base.point.x * 1000.0,
                point_base.point.y * 1000.0,
                point_base.point.z * 1000.0
            ])
        except Exception as e:
            return None
    
    # ========================================
    # ì•ˆì „ ì˜ì—­ í´ë¨í•‘
    # ========================================
    def clamp_to_safety(self, pos: np.ndarray) -> np.ndarray:
        """ì•ˆì „ ì˜ì—­ ë‚´ë¡œ í´ë¨í•‘"""
        result = pos.copy()
        
        # XY í‰ë©´ ë°˜ê²½
        r_xy = np.sqrt(pos[0]**2 + pos[1]**2)
        
        if r_xy < SAFETY_LIMITS['r_min']:
            scale = SAFETY_LIMITS['r_min'] / r_xy if r_xy > 0 else 1.0
            result[0] *= scale
            result[1] *= scale
        elif r_xy > SAFETY_LIMITS['r_max']:
            scale = SAFETY_LIMITS['r_max'] / r_xy
            result[0] *= scale
            result[1] *= scale
        
        # Z ë†’ì´
        result[2] = np.clip(result[2], SAFETY_LIMITS['z_min'], SAFETY_LIMITS['z_max'])
        
        return result
    
    # ========================================
    # ë§ˆì»¤ ë°œí–‰
    # ========================================
    def publish_marker(self, pos_mm: np.ndarray, ns: str, color: tuple, publisher, text_label: str = None, text_publisher=None):
        """ë§ˆì»¤ ë°œí–‰ í—¬í¼ (í…ìŠ¤íŠ¸ ë§ˆì»¤ í¬í•¨)"""
        marker = Marker()
        marker.header.frame_id = self.robot_frame
        marker.header.stamp = self.get_clock().now().to_msg()
        marker.ns = ns
        marker.id = 0
        marker.type = Marker.CUBE
        marker.action = Marker.ADD
        marker.pose.position.x = pos_mm[0] / 1000.0
        marker.pose.position.y = pos_mm[1] / 1000.0
        marker.pose.position.z = pos_mm[2] / 1000.0
        marker.pose.orientation.w = 1.0
        marker.scale.x = marker.scale.y = marker.scale.z = 0.08
        marker.color.r, marker.color.g, marker.color.b, marker.color.a = *color, 0.5
        marker.lifetime.nanosec = 500000000
        publisher.publish(marker)
        
        # í…ìŠ¤íŠ¸ ë§ˆì»¤ ë°œí–‰ (ì›ë³¸ ì½”ë“œ ë³µì›)
        if text_label and text_publisher:
            text = Marker()
            text.header.frame_id = self.robot_frame
            text.header.stamp = self.get_clock().now().to_msg()
            text.ns = ns + "_text"
            text.id = 0
            text.type = Marker.TEXT_VIEW_FACING
            text.action = Marker.ADD
            text.pose.position.x = pos_mm[0] / 1000.0
            text.pose.position.y = pos_mm[1] / 1000.0
            text.pose.position.z = pos_mm[2] / 1000.0 + 0.08  # ë§ˆì»¤ ìœ„ì— í‘œì‹œ
            text.pose.orientation.w = 1.0
            text.scale.z = 0.04
            text.color.r, text.color.g, text.color.b, text.color.a = *color, 1.0
            text.text = text_label
            text.lifetime.nanosec = 500000000
            text_publisher.publish(text)
    
    def publish_line(self, camera_pos_mm: np.ndarray):
        """
        ì¹´ë©”ë¼ â†’ ì–¼êµ´ íˆ¬ì˜ ë¼ì¸ (ë…¸ë€ìƒ‰)
        
        RGB ë Œì¦ˆ ì¤‘ì‹¬ â†’ ì–¼êµ´ ìœ„ì¹˜ê¹Œì§€ì˜ ë¼ì¸
        ì›ë³¸ ì½”ë“œ ë³µì›: camera_link í”„ë ˆì„ì—ì„œ RGB ë Œì¦ˆ ì˜¤í”„ì…‹ ì ìš©
        """
        try:
            # RGB ë Œì¦ˆ ìœ„ì¹˜ë¥¼ camera_linkì—ì„œ base_linkë¡œ ë³€í™˜
            # D435i: RGB ë Œì¦ˆëŠ” camera_link ì¤‘ì‹¬ì—ì„œ Y=-15mm ìœ„ì¹˜
            transform = self.tf_buffer.lookup_transform(
                self.robot_frame, "camera_link",
                rclpy.time.Time(),
                timeout=rclpy.duration.Duration(seconds=0.1)
            )
            
            rgb_point = PointStamped()
            rgb_point.header.frame_id = "camera_link"
            rgb_point.header.stamp = self.get_clock().now().to_msg()
            rgb_point.point.x = 0.0
            rgb_point.point.y = -0.015  # RGB ë Œì¦ˆ ì˜¤í”„ì…‹ (camera_linkì—ì„œ ì˜¤ë¥¸ìª½)
            rgb_point.point.z = 0.0
            
            rgb_transformed = tf2_geometry_msgs.do_transform_point(rgb_point, transform)
            
            rgb_origin_robot = np.array([
                rgb_transformed.point.x * 1000.0,
                rgb_transformed.point.y * 1000.0,
                rgb_transformed.point.z * 1000.0
            ])
        except Exception as e:
            self.get_logger().warn(f"RGB lens TF failed: {e}", throttle_duration_sec=5.0)
            return
        
        # ì–¼êµ´ ìœ„ì¹˜ë„ TF ë³€í™˜
        face_pos_robot = self.camera_to_robot(camera_pos_mm)
        if face_pos_robot is None:
            return
        
        marker = Marker()
        marker.header.frame_id = self.robot_frame
        marker.header.stamp = self.get_clock().now().to_msg()
        marker.ns = "face_line"
        marker.id = 0
        marker.type = Marker.LINE_STRIP
        marker.action = Marker.ADD
        
        p1, p2 = Point(), Point()
        p1.x = rgb_origin_robot[0] / 1000.0
        p1.y = rgb_origin_robot[1] / 1000.0
        p1.z = rgb_origin_robot[2] / 1000.0
        p2.x = face_pos_robot[0] / 1000.0
        p2.y = face_pos_robot[1] / 1000.0
        p2.z = face_pos_robot[2] / 1000.0
        
        marker.points = [p1, p2]
        marker.scale.x = 0.01
        marker.color.r, marker.color.g, marker.color.b, marker.color.a = 1.0, 1.0, 0.0, 1.0
        marker.lifetime.nanosec = 500000000
        self.line_pub.publish(marker)
    
    def delete_markers(self):
        """ëª¨ë“  ë§ˆì»¤ ì‚­ì œ (í…ìŠ¤íŠ¸ í¬í•¨)"""
        # íë¸Œ ë§ˆì»¤ ì‚­ì œ
        for pub, ns in [(self.marker_pub, "face_raw"), 
                        (self.marker_ekf_pub, "face_ekf"),
                        (self.marker_robot_pub, "face_target")]:
            marker = Marker()
            marker.header.frame_id = self.robot_frame
            marker.header.stamp = self.get_clock().now().to_msg()
            marker.ns = ns
            marker.action = Marker.DELETE
            pub.publish(marker)
        
        # í…ìŠ¤íŠ¸ ë§ˆì»¤ ì‚­ì œ (ì›ë³¸ ì½”ë“œ ë³µì›)
        for pub, ns in [(self.text_pub, "face_raw_text"),
                        (self.text_ekf_pub, "face_ekf_text"),
                        (self.text_robot_pub, "face_target_text")]:
            marker = Marker()
            marker.header.frame_id = self.robot_frame
            marker.header.stamp = self.get_clock().now().to_msg()
            marker.ns = ns
            marker.action = Marker.DELETE
            pub.publish(marker)
    
    # ========================================
    # ë©”ì¸ ë£¨í”„
    # ========================================
    def tracking_loop(self):
        """ë©”ì¸ ì¶”ì  ë£¨í”„ (100Hz)"""
        # FPS ì¸¡ì •
        self.loop_count += 1
        current_time = self.get_clock().now()
        time_diff = (current_time - self.last_fps_time).nanoseconds / 1e9
        
        if time_diff >= 1.0:
            success_rate = (self.success_count / self.loop_count * 100) if self.loop_count > 0 else 0
            self.get_logger().info(
                f"ğŸ“Š {self.loop_count/time_diff:.1f}Hz | 3D: {success_rate:.1f}%",
                throttle_duration_sec=2.0)
            self.loop_count = 0
            self.success_count = 0
            self.last_fps_time = current_time
        
        # ì–¼êµ´ ë°ì´í„° í™•ì¸
        if len(self.faces_data) < 4:
            if self.face_detected:
                self.delete_markers()
                self.face_detected = False
            return
        
        self.face_detected = True
        center_x, center_y = self.faces_data[0], self.faces_data[1]
        
        # 3D ìœ„ì¹˜ ê³„ì‚°
        camera_pos = self.get_3d_position(center_x, center_y)
        if camera_pos is None:
            return
        
        self.success_count += 1
        
        # EKF í•„í„°ë§
        if not self.ekf.initialized:
            self.ekf.initialize(camera_pos.tolist())
        else:
            self.ekf.predict()
            self.ekf.update(camera_pos.tolist())
        
        filtered_pos = self.ekf.get_position()
        
        # ë¡œë´‡ ì¢Œí‘œ ë³€í™˜
        robot_raw = self.camera_to_robot(camera_pos)
        robot_filtered = self.camera_to_robot(filtered_pos)
        
        if robot_raw is None or robot_filtered is None:
            return
        
        # ëª©í‘œ ìœ„ì¹˜ ê³„ì‚° (ì•ˆì „ê±°ë¦¬ ì ìš©)
        depth = abs(filtered_pos[2])
        if depth < 100:
            return
        
        distance = np.linalg.norm(filtered_pos)
        direction = filtered_pos / distance
        target_camera = filtered_pos - direction * SAFETY_DISTANCE
        
        robot_target = self.camera_to_robot(target_camera)
        if robot_target is None:
            return
        
        robot_target[2] += 50.0  # Z ì˜¤í”„ì…‹
        robot_target = self.clamp_to_safety(robot_target)
        
        # ë§ˆì»¤ ë°œí–‰ (í…ìŠ¤íŠ¸ í¬í•¨ - ì›ë³¸ ì½”ë“œ ë³µì›)
        self.publish_marker(robot_raw, "face_raw", (0.0, 1.0, 0.0), self.marker_pub, "Raw", self.text_pub)
        self.publish_marker(robot_filtered, "face_ekf", (0.0, 0.8, 0.8), self.marker_ekf_pub, "Filtered", self.text_ekf_pub)
        self.publish_marker(robot_target, "face_target", (1.0, 0.0, 0.0), self.marker_robot_pub, "Target", self.text_robot_pub)
        
        # Line ë§ˆì»¤ ë°œí–‰ (ì›ë³¸ ì½”ë“œ ë³µì› - RGB ë Œì¦ˆ ì˜¤í”„ì…‹ ì ìš©)
        self.publish_line(filtered_pos)
        
        # ë””ë²„ê·¸ ë¡œê·¸
        self.get_logger().info(
            f"ğŸ“ Target: [{robot_target[0]:.0f}, {robot_target[1]:.0f}, {robot_target[2]:.0f}]mm",
            throttle_duration_sec=1.0)


def main(args=None):
    rclpy.init(args=args)
    node = FaceTrackingNode()
    
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        if rclpy.ok():
            rclpy.shutdown()


if __name__ == "__main__":
    main()
