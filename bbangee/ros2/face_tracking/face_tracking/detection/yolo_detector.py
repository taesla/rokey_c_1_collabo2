#!/usr/bin/env python3
"""
YOLO Face Detector - ìˆœìˆ˜ ê°ì§€ ë¡œì§

TensorRT ìµœì í™”ë¥¼ í¬í•¨í•œ YOLOv8 ê¸°ë°˜ ì–¼êµ´ ê°ì§€ê¸°
ROS2 ì˜ì¡´ì„± ì—†ìŒ - ìˆœìˆ˜ Python í´ë˜ìŠ¤

Features:
    - TensorRT ì—”ì§„ ìë™ ë³€í™˜ (NVIDIA GPU)
    - FP16 Half Precision ì¶”ë¡ 
    - ROI ê¸°ë°˜ ë¹ ë¥¸ ì¶”ì 
    - CLAHE ì „ì²˜ë¦¬ (ì¡°ëª… ë³´ì •)
"""
import cv2
import numpy as np
import os
import time
from typing import Optional, Tuple, Dict, List
from dataclasses import dataclass


@dataclass
class Detection:
    """ê°ì§€ ê²°ê³¼ ë°ì´í„° í´ë˜ìŠ¤"""
    x1: int
    y1: int
    x2: int
    y2: int
    confidence: float
    
    @property
    def center(self) -> Tuple[int, int]:
        """ë°”ìš´ë”© ë°•ìŠ¤ ì¤‘ì‹¬ì """
        return ((self.x1 + self.x2) // 2, (self.y1 + self.y2) // 2)
    
    @property
    def width(self) -> int:
        return self.x2 - self.x1
    
    @property
    def height(self) -> int:
        return self.y2 - self.y1
    
    @property
    def area(self) -> int:
        return self.width * self.height


class YoloDetector:
    """
    YOLOv8 ê¸°ë°˜ ì–¼êµ´ ê°ì§€ê¸°
    
    TensorRT ìµœì í™”ì™€ ROI ê¸°ë°˜ ì¶”ì ì„ ì§€ì›í•©ë‹ˆë‹¤.
    """
    
    def __init__(
        self,
        model_path: str = '',
        confidence_threshold: float = 0.4,
        use_gpu: bool = True,
        use_tensorrt: bool = True,
        use_fp16: bool = True,
        input_size: int = 1280,
        use_preprocessing: bool = True,
        use_roi_tracking: bool = True,
        logger=None
    ):
        """
        Args:
            model_path: YOLO ëª¨ë¸ ê²½ë¡œ (.pt ë˜ëŠ” .engine)
            confidence_threshold: ê°ì§€ ì‹ ë¢°ë„ ì„ê³„ê°’
            use_gpu: GPU ì‚¬ìš© ì—¬ë¶€
            use_tensorrt: TensorRT ìµœì í™” ì‚¬ìš©
            use_fp16: FP16 ì¶”ë¡  ì‚¬ìš©
            input_size: ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸°
            use_preprocessing: CLAHE ì „ì²˜ë¦¬ ì ìš©
            use_roi_tracking: ROI ê¸°ë°˜ ì¶”ì  ì‚¬ìš©
            logger: ë¡œê±° (ROS2 logger ë˜ëŠ” print)
        """
        self.confidence_threshold = confidence_threshold
        self.use_tensorrt = use_tensorrt
        self.use_fp16 = use_fp16
        self.input_size = input_size
        self.use_preprocessing = use_preprocessing
        self.use_roi_tracking = use_roi_tracking
        self.logger = logger
        
        # ëª¨ë¸ ê²½ë¡œ ì„¤ì •
        self.model_path = self._resolve_model_path(model_path)
        
        # GPU ì„¤ì •
        self.device, self.cuda_available = self._setup_device(use_gpu)
        
        # TensorRT ë¶ˆê°€ ì‹œ ë¹„í™œì„±í™”
        if not self.cuda_available:
            self.use_tensorrt = False
            self.use_fp16 = False
        
        # ëª¨ë¸ ë¡œë“œ
        self.model = self._load_model()
        
        # CLAHE ì´ˆê¸°í™”
        self.clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))
        
        # ROI ì¶”ì  ìƒíƒœ
        self.last_detection: Optional[Detection] = None
        self.roi_margin = 100  # í”½ì…€
        self.roi_fail_count = 0
        self.max_roi_fail = 3
        
        # ê¹œë¹¡ì„ ë°©ì§€
        self.no_detection_count = 0
        self.max_no_detection = 5
        
        # ì„±ëŠ¥ ì¸¡ì •
        self.inference_times: List[float] = []
        self.avg_inference_time = 0.0
    
    def _log(self, msg: str, level: str = 'info'):
        """ë¡œê·¸ ì¶œë ¥"""
        if self.logger:
            if hasattr(self.logger, level):
                getattr(self.logger, level)(msg)
            else:
                self.logger(msg)
        else:
            print(f"[{level.upper()}] {msg}")
    
    def _resolve_model_path(self, model_path: str) -> str:
        """ëª¨ë¸ ê²½ë¡œ í™•ì¸ ë° ê¸°ë³¸ ê²½ë¡œ ì„¤ì •"""
        if model_path and os.path.exists(model_path):
            return model_path
        
        # ê¸°ë³¸ ê²½ë¡œë“¤
        default_paths = [
            '/home/rokey/ros2_ws/src/face_tracking/models/yolov8n-face.pt',
            '/home/rokey/ros2_ws/src/face_tracking_pkg/models/yolov8n-face.pt',
        ]
        
        for path in default_paths:
            if os.path.exists(path):
                return path
        
        raise FileNotFoundError(f"ëª¨ë¸ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {default_paths}")
    
    def _setup_device(self, use_gpu: bool) -> Tuple[str, bool]:
        """GPU ì„¤ì •"""
        if not use_gpu:
            return 'cpu', False
        
        try:
            import torch
            if torch.cuda.is_available():
                gpu_name = torch.cuda.get_device_name(0)
                self._log(f"ğŸš€ GPU ê°ì§€: {gpu_name}")
                return 'cuda', True
        except Exception as e:
            self._log(f"âš ï¸ GPU í™•ì¸ ì‹¤íŒ¨: {e}", 'warn')
        
        return 'cpu', False
    
    def _load_model(self):
        """ëª¨ë¸ ë¡œë“œ (TensorRT ìš°ì„ )"""
        from ultralytics import YOLO
        
        engine_path = self.model_path.replace('.pt', '.engine')
        
        # TensorRT ì—”ì§„ ë¡œë“œ ì‹œë„
        if self.use_tensorrt and self.cuda_available:
            if os.path.exists(engine_path):
                self._log(f"ğŸ”¥ TensorRT ì—”ì§„ ë¡œë”©: {engine_path}")
                try:
                    model = YOLO(engine_path)
                    self._log("âœ… TensorRT ì—”ì§„ ë¡œë“œ ì„±ê³µ!")
                    return model
                except Exception as e:
                    self._log(f"âš ï¸ TensorRT ë¡œë“œ ì‹¤íŒ¨: {e}", 'warn')
            
            # TensorRT ì—”ì§„ ìƒì„±
            self._log("ğŸ”§ TensorRT ì—”ì§„ ìƒì„± ì¤‘... (1-2ë¶„ ì†Œìš”)")
            try:
                model = YOLO(self.model_path)
                model.export(
                    format='engine',
                    half=self.use_fp16,
                    imgsz=self.input_size,
                    device=0
                )
                if os.path.exists(engine_path):
                    self._log("âœ… TensorRT ì—”ì§„ ìƒì„± ì™„ë£Œ!")
                    return YOLO(engine_path)
            except Exception as e:
                self._log(f"âš ï¸ TensorRT ë³€í™˜ ì‹¤íŒ¨: {e}", 'warn')
        
        # ì¼ë°˜ YOLO ëª¨ë¸
        self._log(f"ğŸ”„ YOLO ëª¨ë¸ ë¡œë”©: {self.model_path}")
        return YOLO(self.model_path)
    
    def preprocess(self, frame: np.ndarray) -> np.ndarray:
        """
        ì´ë¯¸ì§€ ì „ì²˜ë¦¬ (CLAHE ì ì‘í˜• íˆìŠ¤í† ê·¸ë¨ í‰í™œí™”)
        
        ì¡°ëª… ë³€í™”ì— ê°•ê±´í•œ ê°ì§€ë¥¼ ìœ„í•´ ì ìš©
        """
        if not self.use_preprocessing:
            return frame
        
        # LAB ìƒ‰ê³µê°„ ë³€í™˜
        lab = cv2.cvtColor(frame, cv2.COLOR_BGR2LAB)
        lab[:, :, 0] = self.clahe.apply(lab[:, :, 0])
        return cv2.cvtColor(lab, cv2.COLOR_LAB2BGR)
    
    def _get_roi(self, frame_shape: Tuple[int, ...]) -> Optional[Tuple[int, int, int, int]]:
        """ì´ì „ ê°ì§€ ê¸°ë°˜ ROI ê³„ì‚°"""
        if not self.use_roi_tracking or self.last_detection is None:
            return None
        
        h, w = frame_shape[:2]
        det = self.last_detection
        
        x1 = max(0, det.x1 - self.roi_margin)
        y1 = max(0, det.y1 - self.roi_margin)
        x2 = min(w, det.x2 + self.roi_margin)
        y2 = min(h, det.y2 + self.roi_margin)
        
        if (x2 - x1) < 100 or (y2 - y1) < 100:
            return None
        
        return (x1, y1, x2, y2)
    
    def _detect_in_roi(self, frame: np.ndarray, roi: Tuple[int, int, int, int]):
        """ROI ì˜ì—­ì—ì„œ ê°ì§€"""
        x1, y1, x2, y2 = roi
        roi_frame = frame[y1:y2, x1:x2]
        
        results = self.model.predict(
            roi_frame,
            conf=self.confidence_threshold,
            device=self.device,
            half=self.use_fp16 and self.cuda_available,
            verbose=False
        )
        return results, (x1, y1)
    
    def _detect_full(self, frame: np.ndarray):
        """ì „ì²´ í”„ë ˆì„ ê°ì§€"""
        results = self.model.predict(
            frame,
            conf=self.confidence_threshold,
            device=self.device,
            imgsz=self.input_size,
            half=self.use_fp16 and self.cuda_available,
            verbose=False
        )
        return results
    
    def detect(self, frame: np.ndarray) -> Optional[Detection]:
        """
        í”„ë ˆì„ì—ì„œ ì–¼êµ´ ê°ì§€
        
        Args:
            frame: BGR ì´ë¯¸ì§€ (numpy array)
        
        Returns:
            Detection ë˜ëŠ” None
        """
        # ì „ì²˜ë¦¬
        processed = self.preprocess(frame)
        
        # ì¶”ë¡  ì‹œê°„ ì¸¡ì •
        start_time = time.time()
        
        # ROI ê¸°ë°˜ ê°ì§€ ì‹œë„
        results = None
        offset = (0, 0)
        roi = self._get_roi(frame.shape)
        
        if roi is not None:
            results, offset = self._detect_in_roi(processed, roi)
            
            # ROI ì‹¤íŒ¨ ì‹œ ì „ì²´ í”„ë ˆì„
            if not results or len(results) == 0 or \
               results[0].boxes is None or len(results[0].boxes) == 0:
                self.roi_fail_count += 1
                if self.roi_fail_count >= self.max_roi_fail:
                    results = self._detect_full(processed)
                    offset = (0, 0)
                    self.roi_fail_count = 0
            else:
                self.roi_fail_count = 0
        else:
            results = self._detect_full(processed)
        
        # ì¶”ë¡  ì‹œê°„ ê¸°ë¡
        inference_time = (time.time() - start_time) * 1000
        self.inference_times.append(inference_time)
        if len(self.inference_times) > 30:
            self.inference_times.pop(0)
        self.avg_inference_time = sum(self.inference_times) / len(self.inference_times)
        
        # ê²°ê³¼ ì²˜ë¦¬ - ê°€ì¥ í° ì–¼êµ´ ì„ íƒ
        best_detection = None
        max_area = 0
        offset_x, offset_y = offset
        
        if results and len(results) > 0 and results[0].boxes is not None:
            for box in results[0].boxes:
                coords = box.xyxy[0].cpu().numpy().copy()
                x1 = int(coords[0] + offset_x)
                y1 = int(coords[1] + offset_y)
                x2 = int(coords[2] + offset_x)
                y2 = int(coords[3] + offset_y)
                conf = float(box.conf[0].cpu().numpy())
                area = (x2 - x1) * (y2 - y1)
                
                if area > max_area:
                    max_area = area
                    best_detection = Detection(x1, y1, x2, y2, conf)
        
        # ê¹œë¹¡ì„ ë°©ì§€
        if best_detection is None:
            self.no_detection_count += 1
            if self.last_detection and self.no_detection_count <= self.max_no_detection:
                # ì´ì „ ê°ì§€ ìœ ì§€ (ì‹ ë¢°ë„ ê°ì‡ )
                decay = 0.9 ** self.no_detection_count
                best_detection = Detection(
                    self.last_detection.x1,
                    self.last_detection.y1,
                    self.last_detection.x2,
                    self.last_detection.y2,
                    self.last_detection.confidence * decay
                )
        else:
            self.no_detection_count = 0
            self.last_detection = best_detection
        
        return best_detection
    
    def get_stats(self) -> Dict:
        """ì„±ëŠ¥ í†µê³„ ë°˜í™˜"""
        return {
            'avg_inference_ms': self.avg_inference_time,
            'device': self.device,
            'tensorrt': self.use_tensorrt and self.cuda_available,
            'fp16': self.use_fp16 and self.cuda_available,
            'roi_tracking': self.use_roi_tracking,
        }
