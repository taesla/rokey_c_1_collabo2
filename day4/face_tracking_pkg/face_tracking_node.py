#!/usr/bin/env python3
"""
Face Tracking Node - 2D ì¢Œí‘œë¥¼ 3D ë¡œë´‡ ì¢Œí‘œê³„ë¡œ ë³€í™˜

TF2ë¥¼ ì‚¬ìš©í•˜ì—¬ ì¹´ë©”ë¼ ì¢Œí‘œê³„ â†’ ë¡œë´‡ ë² ì´ìŠ¤ ì¢Œí‘œê³„ ë³€í™˜

Subscribed Topics:
  /face_detection/faces - ì–¼êµ´ 2D ì¢Œí‘œ (from face_detection_node)
  /camera/camera/aligned_depth_to_color/image_raw - ê¹Šì´ ì´ë¯¸ì§€
  /camera/camera/color/camera_info - ì¹´ë©”ë¼ ë‚´ë¶€ íŒŒë¼ë¯¸í„°

Published Topics:
  /face_tracking/marker - RViz ë§ˆì»¤ (ì¹´ë©”ë¼ í”„ë ˆì„, ì´ˆë¡ìƒ‰)
  /face_tracking/marker_robot - RViz ë§ˆì»¤ (ë¡œë´‡ ë² ì´ìŠ¤ í”„ë ˆì„, ë¹¨ê°„ìƒ‰) â† ë¡œë´‡ ëª©í‘œ ìœ„ì¹˜!
  /face_tracking/line - ì¹´ë©”ë¼â†’ì–¼êµ´ ì—°ê²°ì„  (ë…¸ë€ìƒ‰)
"""
import numpy as np
import rclpy
from rclpy.node import Node
from sensor_msgs.msg import Image, CameraInfo
from std_msgs.msg import Float32MultiArray
from visualization_msgs.msg import Marker
from geometry_msgs.msg import Point, PointStamped
from cv_bridge import CvBridge
import tf2_ros
import tf2_geometry_msgs
from face_tracking_pkg.face_tracking_ekf import FaceTrackingEKF


class FaceTrackingNode(Node):
    def __init__(self):
        super().__init__('face_tracking_node')
        
        self.bridge = CvBridge()
        
        # íŒŒë¼ë¯¸í„° ì„ ì–¸
        self.declare_parameter('target_offset_mm', 650.0)
        self.declare_parameter('camera_frame', 'camera_color_optical_frame')
        self.declare_parameter('robot_frame', 'base_link')
        
        self.target_offset_mm = self.get_parameter('target_offset_mm').value
        self.camera_frame = self.get_parameter('camera_frame').value
        self.robot_frame = self.get_parameter('robot_frame').value
        
        # ë°ì´í„° ì €ì¥
        self.faces_data = []
        self.depth_frame = None
        self.intrinsics = None
        
        # TF2 ë²„í¼ ë° ë¦¬ìŠ¤ë„ˆ
        self.tf_buffer = tf2_ros.Buffer()
        self.tf_listener = tf2_ros.TransformListener(self.tf_buffer, self)
        
        # êµ¬ë…ì
        self.faces_sub = self.create_subscription(
            Float32MultiArray, '/face_detection/faces', self.faces_callback, 10)
        self.depth_sub = self.create_subscription(
            Image, '/camera/camera/aligned_depth_to_color/image_raw', self.depth_callback, 10)
        self.camera_info_sub = self.create_subscription(
            CameraInfo, '/camera/camera/color/camera_info', self.camera_info_callback, 10)
        
        # ë°œí–‰ì
        self.marker_pub = self.create_publisher(Marker, '/face_tracking/marker', 10)
        self.marker_robot_pub = self.create_publisher(Marker, '/face_tracking/marker_robot', 10)
        self.marker_ekf_pub = self.create_publisher(Marker, '/face_tracking/marker_ekf', 10)  # EKF í•„í„°ë§ëœ ì¹´ë©”ë¼ í”„ë ˆì„
        # í…ìŠ¤íŠ¸ ì „ìš© í† í”½
        self.text_pub = self.create_publisher(Marker, '/face_tracking/text', 10)
        self.text_ekf_pub = self.create_publisher(Marker, '/face_tracking/text_ekf', 10)
        self.text_robot_pub = self.create_publisher(Marker, '/face_tracking/text_robot', 10)
        self.line_pub = self.create_publisher(Marker, '/face_tracking/line', 10)
        
        # EKF ì´ˆê¸°í™” (ì¹´ë©”ë¼ í”„ë ˆì„ ì¢Œí‘œ í•„í„°ë§ìš©)
        self.camera_ekf = FaceTrackingEKF(dt=0.033, dim=3)
        
        # íƒ€ì´ë¨¸: íŠ¸ë˜í‚¹ ë£¨í”„ (30Hz) - ë³‘ëª© í•´ê²°
        self.timer = self.create_timer(0.033, self.tracking_loop)
        
        # ì„±ëŠ¥ ì¸¡ì •
        self.loop_count = 0
        self.last_fps_time = self.get_clock().now()
        self.tracking_fps = 0.0
        
        self.get_logger().info("=" * 60)
        self.get_logger().info("ğŸ”„ Face Tracking Node (TF2) ì‹œì‘! [30Hz]")
        self.get_logger().info("  ğŸŸ¢ ì´ˆë¡ ë§ˆì»¤: ì¹´ë©”ë¼ í”„ë ˆì„")
        self.get_logger().info("  ğŸ”´ ë¹¨ê°„ ë§ˆì»¤: ë¡œë´‡ ë² ì´ìŠ¤ í”„ë ˆì„ (ëª©í‘œ)")
        self.get_logger().info("=" * 60)
    
    def faces_callback(self, msg):
        self.faces_data = list(msg.data)
    
    def depth_callback(self, msg):
        try:
            self.depth_frame = self.bridge.imgmsg_to_cv2(msg, desired_encoding='passthrough')
        except Exception as e:
            self.get_logger().error(f"ê¹Šì´ ì´ë¯¸ì§€ ë³€í™˜ ì‹¤íŒ¨: {e}")
    
    def camera_info_callback(self, msg):
        self.intrinsics = {
            'fx': msg.k[0], 'fy': msg.k[4],
            'ppx': msg.k[2], 'ppy': msg.k[5]
        }
    
    def get_3d_position(self, center_x, center_y):
        """2D í”½ì…€ ì¢Œí‘œ â†’ 3D ì¹´ë©”ë¼ ì¢Œí‘œ (mm)"""
        if self.depth_frame is None or self.intrinsics is None:
            return None
        
        x, y = int(center_x), int(center_y)
        h, w = self.depth_frame.shape
        
        if x < 5 or x >= w - 5 or y < 5 or y >= h - 5:
            return None
        
        # ìµœì í™”: 5x5 ì˜ì—­ì—ì„œ median ëŒ€ì‹  ì¤‘ì‹¬ 3x3ë§Œ ì‚¬ìš©
        depth_region = self.depth_frame[y-1:y+2, x-1:x+2]
        valid_depths = depth_region[depth_region > 0]
        
        if len(valid_depths) == 0:
            return None
        
        # ê°œì„ : Trimmed Mean (ìƒí•˜ìœ„ 20% ì œê±° í›„ í‰ê· )
        # medianë³´ë‹¤ ë¹ ë¥´ë©´ì„œë„ ì´ìƒì¹˜ì— ê°•ê±´
        if len(valid_depths) >= 5:
            valid_depths_sorted = np.sort(valid_depths)
            trim_count = max(1, len(valid_depths) // 5)  # 20% ì œê±°
            trimmed = valid_depths_sorted[trim_count:-trim_count]
            depth_mm = float(np.mean(trimmed))
        else:
            # ìƒ˜í”Œ ì ìœ¼ë©´ ê·¸ëƒ¥ mean
            depth_mm = float(np.mean(valid_depths))
        
        camera_x = (center_x - self.intrinsics['ppx']) * depth_mm / self.intrinsics['fx']
        camera_y = (center_y - self.intrinsics['ppy']) * depth_mm / self.intrinsics['fy']
        camera_z = depth_mm
        
        return np.array([camera_x, camera_y, camera_z])
    
    def camera_to_robot_tf2(self, camera_pos_mm):
        """TF2ë¥¼ ì‚¬ìš©í•´ ì¹´ë©”ë¼ ì¢Œí‘œ â†’ ë¡œë´‡ ë² ì´ìŠ¤ ì¢Œí‘œ ë³€í™˜"""
        try:
            point_camera = PointStamped()
            point_camera.header.frame_id = self.camera_frame
            point_camera.header.stamp = self.get_clock().now().to_msg()
            point_camera.point.x = camera_pos_mm[0] / 1000.0
            point_camera.point.y = camera_pos_mm[1] / 1000.0
            point_camera.point.z = camera_pos_mm[2] / 1000.0
            
            # ìµœì í™”: íƒ€ì„ì•„ì›ƒ ë‹¨ì¶• (0.1ì´ˆ â†’ 0.01ì´ˆ)
            transform = self.tf_buffer.lookup_transform(
                self.robot_frame, self.camera_frame,
                rclpy.time.Time(),
                timeout=rclpy.duration.Duration(seconds=0.01)
            )
            
            point_base = tf2_geometry_msgs.do_transform_point(point_camera, transform)
            
            return np.array([
                point_base.point.x * 1000.0,
                point_base.point.y * 1000.0,
                point_base.point.z * 1000.0
            ])
            
        except (tf2_ros.LookupException, tf2_ros.ConnectivityException, 
                tf2_ros.ExtrapolationException) as e:
            self.get_logger().warn(f"TF2 ë³€í™˜ ì‹¤íŒ¨: {e}")
            return None
    
    def publish_camera_marker(self, camera_pos):
        """ì¹´ë©”ë¼ í”„ë ˆì„ ë§ˆì»¤ (ì´ˆë¡ìƒ‰ íë¸Œ)"""
        marker = Marker()
        marker.header.frame_id = self.camera_frame
        marker.header.stamp = self.get_clock().now().to_msg()
        marker.ns = "face_camera"
        marker.id = 0
        marker.type = Marker.CUBE
        marker.action = Marker.ADD
        marker.pose.position.x = camera_pos[0] / 1000.0
        marker.pose.position.y = camera_pos[1] / 1000.0
        marker.pose.position.z = camera_pos[2] / 1000.0
        # ì¹´ë©”ë¼ optical í”„ë ˆì„ íšŒì „ ë³´ì • (Xì¶• 180ë„)
        marker.pose.orientation.x = 1.0
        marker.pose.orientation.y = 0.0
        marker.pose.orientation.z = 0.0
        marker.pose.orientation.w = 0.0
        marker.scale.x = marker.scale.y = marker.scale.z = 0.08
        marker.color.r, marker.color.g, marker.color.b, marker.color.a = 0.0, 1.0, 0.0, 0.5
        marker.lifetime.sec = 0
        marker.lifetime.nanosec = 0
        self.marker_pub.publish(marker)
        
        # í…ìŠ¤íŠ¸ ë§ˆì»¤ (ë³„ë„ í† í”½) - base_link
        text = Marker()
        text.header.frame_id = self.robot_frame
        text.header.stamp = self.get_clock().now().to_msg()
        text.ns = "face_camera_text"
        text.id = 0
        text.type = Marker.TEXT_VIEW_FACING
        text.action = Marker.ADD
        text.pose.position.x = robot_pos[0] / 1000.0
        text.pose.position.y = robot_pos[1] / 1000.0
        text.pose.position.z = robot_pos[2] / 1000.0 + 0.08
        text.pose.orientation.w = 1.0
        text.scale.z = 0.04
        text.color.r, text.color.g, text.color.b, text.color.a = 0.0, 1.0, 0.0, 1.0
        text.text = "Raw"
        text.lifetime.sec = 0
        text.lifetime.nanosec = 0
        self.text_pub.publish(text)
    
    def publish_camera_ekf_marker(self, filtered_pos):
        """ì¹´ë©”ë¼ í”„ë ˆì„ EKF í•„í„°ë§ ë§ˆì»¤ (ì²­ë¡ìƒ‰ íë¸Œ)"""
        marker = Marker()
        marker.header.frame_id = self.camera_frame
        marker.header.stamp = self.get_clock().now().to_msg()
        marker.ns = "face_camera_ekf"
        marker.id = 0
        marker.type = Marker.CUBE
        marker.action = Marker.ADD
        marker.pose.position.x = filtered_pos[0] / 1000.0
        marker.pose.position.y = filtered_pos[1] / 1000.0
        marker.pose.position.z = filtered_pos[2] / 1000.0
        # ì¹´ë©”ë¼ optical í”„ë ˆì„ íšŒì „ ë³´ì •
        marker.pose.orientation.x = 1.0
        marker.pose.orientation.y = 0.0
        marker.pose.orientation.z = 0.0
        marker.pose.orientation.w = 0.0
        marker.scale.x = marker.scale.y = marker.scale.z = 0.10
        marker.color.r, marker.color.g, marker.color.b, marker.color.a = 0.0, 0.8, 0.8, 0.5
        marker.lifetime.sec = 0
        marker.lifetime.nanosec = 0
        self.marker_ekf_pub.publish(marker)
        
        # í…ìŠ¤íŠ¸ ë§ˆì»¤ (ë³„ë„ í† í”½) - base_link
        text = Marker()
        text.header.frame_id = self.robot_frame
        text.header.stamp = self.get_clock().now().to_msg()
        text.ns = "face_camera_ekf_text"
        text.id = 0
        text.type = Marker.TEXT_VIEW_FACING
        text.action = Marker.ADD
        text.pose.position.x = robot_pos[0] / 1000.0
        text.pose.position.y = robot_pos[1] / 1000.0
        text.pose.position.z = robot_pos[2] / 1000.0 + 0.10
        text.pose.orientation.w = 1.0
        text.scale.z = 0.04
        text.color.r, text.color.g, text.color.b, text.color.a = 0.0, 1.0, 1.0, 1.0
        text.text = "Filtered"
        text.lifetime.sec = 0
        text.lifetime.nanosec = 0
        self.text_ekf_pub.publish(text)
    
    def publish_robot_marker(self, robot_pos):
        """ë¡œë´‡ ë² ì´ìŠ¤ í”„ë ˆì„ ë§ˆì»¤ (ë¹¨ê°„ìƒ‰ íë¸Œ)"""
        marker = Marker()
        marker.header.frame_id = self.robot_frame
        marker.header.stamp = self.get_clock().now().to_msg()
        marker.ns = "face_robot_target"
        marker.id = 0
        marker.type = Marker.CUBE
        marker.action = Marker.ADD
        marker.pose.position.x = robot_pos[0] / 1000.0
        marker.pose.position.y = robot_pos[1] / 1000.0
        marker.pose.position.z = robot_pos[2] / 1000.0
        marker.pose.orientation.w = 1.0
        marker.scale.x = marker.scale.y = marker.scale.z = 0.10
        marker.color.r, marker.color.g, marker.color.b, marker.color.a = 1.0, 0.0, 0.0, 0.5
        marker.lifetime.sec = 0
        marker.lifetime.nanosec = 0
        self.marker_robot_pub.publish(marker)
        
        # í…ìŠ¤íŠ¸ ë§ˆì»¤ (ë³„ë„ í† í”½)
        text = Marker()
        text.header.frame_id = self.robot_frame
        text.header.stamp = self.get_clock().now().to_msg()
        text.ns = "face_robot_text"
        text.id = 0
        text.type = Marker.TEXT_VIEW_FACING
        text.action = Marker.ADD
        text.pose.position.x = robot_pos[0] / 1000.0
        text.pose.position.y = robot_pos[1] / 1000.0
        text.pose.position.z = robot_pos[2] / 1000.0 + 0.10
        text.pose.orientation.w = 1.0
        text.scale.z = 0.05
        text.color.r, text.color.g, text.color.b, text.color.a = 1.0, 0.0, 0.0, 1.0
        text.text = "Raw"
        text.lifetime.sec = 0
        text.lifetime.nanosec = 0
        self.text_robot_pub.publish(text)
    
    def publish_line_marker(self, camera_pos):
        """ì¹´ë©”ë¼â†’ì–¼êµ´ ë¼ì¸ (ë…¸ë€ìƒ‰)"""
        marker = Marker()
        marker.header.frame_id = self.camera_frame
        marker.header.stamp = self.get_clock().now().to_msg()
        marker.ns = "face_line"
        marker.id = 2
        marker.type = Marker.LINE_STRIP
        marker.action = Marker.ADD
        
        p1 = Point()
        p2 = Point()
        p2.x, p2.y, p2.z = camera_pos[0]/1000.0, camera_pos[1]/1000.0, camera_pos[2]/1000.0
        marker.points = [p1, p2]
        
        marker.scale.x = 0.01
        marker.color.r, marker.color.g, marker.color.b, marker.color.a = 1.0, 1.0, 0.0, 1.0
        marker.lifetime.nanosec = 500000000
        self.line_pub.publish(marker)
    
    def tracking_loop(self):
        """ë©”ì¸ íŠ¸ë˜í‚¹ ë£¨í”„ (30Hz)"""
        # FPS ì¸¡ì •
        self.loop_count += 1
        current_time = self.get_clock().now()
        time_diff = (current_time - self.last_fps_time).nanoseconds / 1e9
        
        # ì„±ê³µ/ì‹¤íŒ¨ ì¹´ìš´í„° ì´ˆê¸°í™”
        if not hasattr(self, 'success_count'):
            self.success_count = 0
            self.fail_count = 0
        
        if time_diff >= 1.0:
            self.tracking_fps = self.loop_count / time_diff
            success_rate = (self.success_count / self.loop_count * 100) if self.loop_count > 0 else 0
            self.get_logger().info(
                f"ğŸ“Š Loop: {self.tracking_fps:.1f}Hz | "
                f"3D Success: {self.success_count}/{self.loop_count} ({success_rate:.1f}%)"
            )
            self.loop_count = 0
            self.success_count = 0
            self.fail_count = 0
            self.last_fps_time = current_time
        
        # ì–¼êµ´ ê°ì§€ ì‹¤íŒ¨ ì‹œ ì¡°ê¸° ë¦¬í„´ (EKF ë§ˆì»¤ë„ í‘œì‹œ ì•ˆ í•¨)
        if len(self.faces_data) < 4:
            return
        
        center_x, center_y = self.faces_data[0], self.faces_data[1]
        
        camera_pos = self.get_3d_position(center_x, center_y)
        if camera_pos is None:
            self.fail_count += 1
            return
        
        self.success_count += 1
        
        # EKF ì—…ë°ì´íŠ¸ (ì¸¡ì •ê°’ìœ¼ë¡œ ë³´ì •)
        camera_pos_array = np.array(camera_pos)
        
        if not self.camera_ekf.initialized:
            self.camera_ekf.initialize(camera_pos_array.tolist())
        else:
            # Predict & Update
            self.camera_ekf.predict()
            self.camera_ekf.update(camera_pos_array.tolist())
        
        # Raw ì´ˆë¡ìƒ‰ ë§ˆì»¤ (ì›ë³¸)
        self.publish_camera_marker(camera_pos)
        
        # EKF ì²­ë¡ìƒ‰ ë§ˆì»¤ (ì¸¡ì •ê°’ ìˆì„ ë•Œë§Œ)
        filtered_camera_pos = self.camera_ekf.get_position()
        self.publish_camera_ekf_marker(filtered_camera_pos)
        
        # Line ë§ˆì»¤ë„ EKF í•„í„°ëœ ìœ„ì¹˜ ì‚¬ìš© (ì²­ë¡ìƒ‰ ë§ˆì»¤ì™€ ì‹±í¬)
        self.publish_line_marker(filtered_camera_pos)
        
        # ëª©í‘œ ìœ„ì¹˜ ê³„ì‚° (ì–¼êµ´ì—ì„œ offsetë§Œí¼ ë–¨ì–´ì§„ ìœ„ì¹˜)
        distance = np.linalg.norm(camera_pos)
        if distance < 1.0:
            return
        
        direction = camera_pos / distance
        target_camera_pos = camera_pos - direction * self.target_offset_mm
        
        robot_pos = self.camera_to_robot_tf2(target_camera_pos)
        if robot_pos is None:
            return
        
        self.publish_robot_marker(robot_pos)


def main(args=None):
    rclpy.init(args=args)
    node = FaceTrackingNode()
    
    try:
        rclpy.spin(node)
    except KeyboardInterrupt:
        pass
    finally:
        node.destroy_node()
        if rclpy.ok():
            rclpy.shutdown()


if __name__ == "__main__":
    main()
